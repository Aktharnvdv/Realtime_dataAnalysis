{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1caa6573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 17 18:40:54 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          Off  | 00000000:17:00.0 Off |                    0 |\n",
      "|  0%   46C    P0    59W / 150W |   5089MiB / 22731MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A10          Off  | 00000000:31:00.0 Off |                    0 |\n",
      "|  0%   46C    P0    57W / 150W |   4581MiB / 22731MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A10          Off  | 00000000:B1:00.0 Off |                    0 |\n",
      "|  0%   42C    P0    57W / 150W |   4581MiB / 22731MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A10          Off  | 00000000:CA:00.0 Off |                    0 |\n",
      "|  0%   44C    P0    60W / 150W |   4581MiB / 22731MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     46524      C   ...min1/anaconda3/bin/python     5087MiB |\n",
      "|    1   N/A  N/A     46524      C   ...min1/anaconda3/bin/python     4579MiB |\n",
      "|    2   N/A  N/A     46524      C   ...min1/anaconda3/bin/python     4579MiB |\n",
      "|    3   N/A  N/A     46524      C   ...min1/anaconda3/bin/python     4579MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Requirement already satisfied: tabulate in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (0.8.9)\n",
      "Requirement already satisfied: tensorboard in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.58.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.26.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (61.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.0.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (4.24.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.27.1)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/aiadmin1/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!pip install tabulate\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8c19f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import random_split, DataLoader,TensorDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "from datetime import time\n",
    "from dateutil.parser import parse\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd70cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    df.columns = ['CITIZENID', 'WILAYAT_CODE','TIMESTAMP', 'AGE', 'SEX', 'VOTE_REG_YR','REGIONID']\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    df['AGE'] = pd.to_numeric(df['AGE'], errors='coerce')\n",
    "    custom_column_names = [\"Time\",\"CITIZENID\",\"REGION_ID\",\"WILAYAT_CODE\",\"Male\",\"Female\",\"20-30\",\"30-40\",\n",
    "                           \"40-50\",\"50-60\",\"60-70\",\"70-80\",\"80+\"]\n",
    "\n",
    "    new_df = pd.DataFrame(columns=custom_column_names)\n",
    "    new_df['Time'] = df['TIMESTAMP'].dt.strftime('%H:%M')\n",
    "    new_df['CITIZENID'] = df['CITIZENID']\n",
    "    new_df['REGION_ID'] = df['REGIONID']\n",
    "    \n",
    "    new_df['WILAYAT_CODE'] = df['WILAYAT_CODE']\n",
    "    new_df['Male'] = (df['SEX'] == 1).astype(int)\n",
    "    new_df['Female'] = (df['SEX'] != 1).astype(int)\n",
    "    labels = [\"20-30\", \"30-40\", \"40-50\", \"50-60\", \"60-70\", \"70-80\", \"80+\"]\n",
    "\n",
    "    for label in labels:\n",
    "        if label != \"80+\":\n",
    "            age_group_mask = (df['AGE'] >= int(label.split('-')[0])) & (df['AGE'] < int(label.split('-')[1]))\n",
    "        else:\n",
    "            age_group_mask = df['AGE'] >= 80\n",
    "        new_df[label] = age_group_mask.astype(int)\n",
    "\n",
    "    new_df.sort_values(by=['WILAYAT_CODE', 'Time'], inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f443d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['/home/aiadmin1/Desktop/ND/edata_2022.xlsx','/home/aiadmin1/Desktop/ND/edata_2012.xlsx','/home/aiadmin1/Desktop/ND/edata_2015.xlsx',\n",
    "               '/home/aiadmin1/Desktop/ND/edata_2016.xlsx','/home/aiadmin1/Desktop/ND/edata_2019.xlsx','/home/aiadmin1/Desktop/ND/edata_2011.xlsx']\n",
    "data_frames = [preprocess_data(file_path) for file_path in file_paths]\n",
    "wilayat_data_frames = {}\n",
    "start_time = '07:00'\n",
    "end_time = '18:59'\n",
    "all_times = [f\"{hour:02d}:{minute:02d}\" for hour in range(7, 19) for minute in range(0, 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9813c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 540\n",
    "epochs = 5000\n",
    "window_size = 60\n",
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2f3dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=60):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1)].squeeze(1).unsqueeze(0)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, output_dim):\n",
    "        super(TransformerPredictor, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers)\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.transformer.encoder(x)\n",
    "        x = self.fc(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22fb7622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7.52 million trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = TransformerPredictor(input_dim=9, d_model=128, nhead=16, num_encoder_layers=6, output_dim=9)\n",
    "params_in_millions = count_parameters(model) / 1e6\n",
    "print(f'The model has {params_in_millions:.2f} million trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ef9f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_replacement(df, wilayat_id):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_out = df.copy()\n",
    "    df_out[((df_out < (Q1 - 1.5 * IQR)) | (df_out > (Q3 + 1.5 * IQR)))] = 0\n",
    "    \n",
    "    scaler_path = f\"/home/aiadmin1/Desktop/OMAN_AI_PROJECT/minmax/scaler_{wilayat_id}.pkl\"\n",
    "    if os.path.exists(scaler_path):\n",
    "        with open(scaler_path, \"rb\") as f:\n",
    "            scaler = pickle.load(f)\n",
    "        df_normalized = scaler.transform(df_out)\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "        df_normalized = scaler.fit_transform(df_out)\n",
    "        with open(scaler_path, \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "        \n",
    "    model_path = f'/home/aiadmin1/Desktop/OMAN_AI_PROJECT/Transformer44M_2/model_{wilayat_id}.pt'\n",
    "    print(f'model_{wilayat_id} is training for dataset of {dataset_i}')\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        model = torch.load(model_path)\n",
    "        print(f\"Model for {wilayat_id} loaded from saved state.\")\n",
    "    else:\n",
    "        model = TransformerPredictor(input_dim=9, d_model=128, nhead=16, num_encoder_layers=6, output_dim=9)\n",
    "        print(f\"Created new model for {wilayat_id}.\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    wilayat_models[wilayat_id] = model\n",
    "    future_pred_window = 60\n",
    "    input_sequences = []\n",
    "    target_sequences = []\n",
    "\n",
    "    for i in range(0, len(df_normalized) - 60- 60 + 1):\n",
    "        input_data = df_normalized[i: i + 60]\n",
    "        target_data = df_normalized[i + 60 : i + 60+ 60]\n",
    "        input_sequences.append(input_data)\n",
    "        target_sequences.append(target_data)\n",
    "        \n",
    "    input_sequences = np.array(input_sequences)\n",
    "    target_sequences = np.array(target_sequences)\n",
    "    input_tensor = torch.Tensor(input_sequences)\n",
    "    target_tensor = torch.Tensor(target_sequences)\n",
    "    \n",
    "    return input_tensor ,target_tensor , scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1 is training for dataset of 0\n",
      "Model for 1 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[131  99  30  66  53  27   2   0   0]\n",
      "Training loss 0.07858190685510635 Testing loss 0.09208472818136215 0 model_1 model saved\n",
      "[131 122  18  51  87  34  25   0   0]\n",
      "Training loss 0.027131086215376854 Testing loss 0.07069817185401917 1000 model_1 model saved\n",
      "[133 122  17  53  87  35  25   0   0]\n",
      "Training loss 0.02278168313205242 Testing loss 0.06873799115419388 2000 model_1 model saved\n",
      "[133 124  16  53  86  36  25   0   0]\n",
      "Training loss 0.021267706528306007 Testing loss 0.06874633580446243 3000 model_1 model saved\n",
      "[132 123  16  53  85  36  24   0   0]\n",
      "Training loss 0.020471543073654175 Testing loss 0.068888358771801 4000 model_1 model saved\n",
      "model_2 is training for dataset of 0\n",
      "Model for 2 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[259 177  94 133  89  67  23   0   0]\n",
      "Training loss 0.08162082731723785 Testing loss 0.08109875023365021 0 model_2 model saved\n",
      "[283 180  66 138 117  77  30   0   0]\n",
      "Training loss 0.014488530345261097 Testing loss 0.05698120966553688 1000 model_2 model saved\n",
      "[282 175  66 138 111  74  31   0   0]\n",
      "Training loss 0.008882899768650532 Testing loss 0.051336608827114105 2000 model_2 model saved\n",
      "[281 175  65 137 109  73  31   0   0]\n",
      "Training loss 0.006631292402744293 Testing loss 0.04922237619757652 3000 model_2 model saved\n",
      "[280 176  65 137 108  73  31   0   0]\n",
      "Training loss 0.005294352769851685 Testing loss 0.04805775359272957 4000 model_2 model saved\n",
      "model_3 is training for dataset of 0\n",
      "Model for 3 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[204 122  65 109  76  39  19   0   0]\n",
      "Training loss 0.11845571547746658 Testing loss 0.1098782941699028 0 model_3 model saved\n",
      "[176 112  16  68  67  64  32   0   0]\n",
      "Training loss 0.02418701909482479 Testing loss 0.0700874850153923 1000 model_3 model saved\n",
      "[178 107  17  68  66  66  33   0   0]\n",
      "Training loss 0.017056111246347427 Testing loss 0.06727602332830429 2000 model_3 model saved\n",
      "[180 107  17  68  65  68  33   0   0]\n",
      "Training loss 0.014303876087069511 Testing loss 0.06503230333328247 3000 model_3 model saved\n",
      "[180 106  17  67  65  69  34   0   0]\n",
      "Training loss 0.012907620519399643 Testing loss 0.06440969556570053 4000 model_3 model saved\n",
      "model_4 is training for dataset of 0\n",
      "Model for 4 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[116  60  24  64  33  27   1   0   0]\n",
      "Training loss 0.09556743502616882 Testing loss 0.08705399930477142 0 model_4 model saved\n",
      "[147  70  27  62  62  34  22   0   0]\n",
      "Training loss 0.029169416055083275 Testing loss 0.060283880680799484 1000 model_4 model saved\n",
      "[144  71  25  60  62  34  21   0   0]\n",
      "Training loss 0.0231570266187191 Testing loss 0.061937958002090454 2000 model_4 model saved\n",
      "[143  71  24  60  64  33  21   0   0]\n",
      "Training loss 0.021124644204974174 Testing loss 0.06145079806447029 3000 model_4 model saved\n",
      "[143  71  24  60  64  33  21   0   0]\n",
      "Training loss 0.020084096118807793 Testing loss 0.06103478744626045 4000 model_4 model saved\n",
      "model_5 is training for dataset of 0\n",
      "Model for 5 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[98 77 31 66 32 19  0  0  0]\n",
      "Training loss 0.06219790130853653 Testing loss 0.05931796133518219 0 model_5 model saved\n",
      "[99 84 19 57 53 27  0  0  0]\n",
      "Training loss 0.023316897451877594 Testing loss 0.04373287037014961 1000 model_5 model saved\n",
      "[104  84  20  57  54  27   0   0   0]\n",
      "Training loss 0.020568516105413437 Testing loss 0.04505692049860954 2000 model_5 model saved\n",
      "[104  84  20  58  54  27   0   0   0]\n",
      "Training loss 0.01954813301563263 Testing loss 0.04619782790541649 3000 model_5 model saved\n",
      "[104  83  19  57  54  27   0   0   0]\n",
      "Training loss 0.01900164969265461 Testing loss 0.046719990670681 4000 model_5 model saved\n",
      "model_6 is training for dataset of 0\n",
      "Model for 6 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[201 157  81 111  80  49  25   2   0]\n",
      "Training loss 0.0695410966873169 Testing loss 0.052301302552223206 0 model_6 model saved\n",
      "[241 253  61 144 129  76  42  23   0]\n",
      "Training loss 0.01252689491957426 Testing loss 0.04307427629828453 1000 model_6 model saved\n",
      "[245 256  56 147 133  77  44  22   0]\n",
      "Training loss 0.0065362961031496525 Testing loss 0.039248816668987274 2000 model_6 model saved\n",
      "[246 256  57 148 133  76  43  21   0]\n",
      "Training loss 0.0044126431457698345 Testing loss 0.036495141685009 3000 model_6 model saved\n",
      "[246 257  58 149 133  78  43  20   0]\n",
      "Training loss 0.003273732727393508 Testing loss 0.03493844345211983 4000 model_6 model saved\n",
      "model_7 is training for dataset of 0\n",
      "Model for 7 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[408 268 130 199 136  98  56  20   0]\n",
      "Training loss 0.13007479906082153 Testing loss 0.11387867480516434 0 model_7 model saved\n",
      "[446 322  74 204 229 114  78  25   0]\n",
      "Training loss 0.018289616331458092 Testing loss 0.06968885660171509 1000 model_7 model saved\n",
      "[452 328  74 205 236 122  80  25   0]\n",
      "Training loss 0.009055246599018574 Testing loss 0.06111225485801697 2000 model_7 model saved\n",
      "[453 328  74 207 234 125  79  25   0]\n",
      "Training loss 0.0058795977383852005 Testing loss 0.05653862655162811 3000 model_7 model saved\n",
      "[447 331  74 206 230 124  80  25   0]\n",
      "Training loss 0.0043107857927680016 Testing loss 0.05383267626166344 4000 model_7 model saved\n",
      "model_8 is training for dataset of 0\n",
      "Model for 8 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[232 172  80 115  81  54  32  15   0]\n",
      "Training loss 0.16913266479969025 Testing loss 0.11874829977750778 0 model_8 model saved\n",
      "[234 144  32  96 110  64  35  -1   0]\n",
      "Training loss 0.027896985411643982 Testing loss 0.07428818196058273 1000 model_8 model saved\n",
      "[248 146  35  94 116  69  35   0   0]\n",
      "Training loss 0.015995709225535393 Testing loss 0.07230540364980698 2000 model_8 model saved\n",
      "[248 147  36  92 114  69  36   0   0]\n",
      "Training loss 0.011234995909035206 Testing loss 0.06881345808506012 3000 model_8 model saved\n",
      "[245 149  36  91 112  70  35   0   0]\n",
      "Training loss 0.00860005896538496 Testing loss 0.0664873719215393 4000 model_8 model saved\n",
      "model_9 is training for dataset of 0\n",
      "Model for 9 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[404 228 155 196  96  93  61  24   0]\n",
      "Training loss 0.11879334598779678 Testing loss 0.12673059105873108 0 model_9 model saved\n",
      "[410 273  74 204 187  82  66  29   0]\n",
      "Training loss 0.017046818509697914 Testing loss 0.07994387298822403 1000 model_9 model saved\n",
      "[406 270  72 206 184  82  63  30   0]\n",
      "Training loss 0.00900411419570446 Testing loss 0.07278992980718613 2000 model_9 model saved\n",
      "[397 271  71 208 181  80  61  31   0]\n",
      "Training loss 0.006266304291784763 Testing loss 0.07008177787065506 3000 model_9 model saved\n",
      "[390 270  70 208 178  78  61  31   0]\n",
      "Training loss 0.0047141071408987045 Testing loss 0.06871646642684937 4000 model_9 model saved\n",
      "model_10 is training for dataset of 0\n",
      "Model for 10 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[205 131  75  79  48  33  19   0   0]\n",
      "Training loss 0.1173843964934349 Testing loss 0.10737162083387375 0 model_10 model saved\n",
      "[194 133  37 106  79  40  17   0   0]\n",
      "Training loss 0.022611496970057487 Testing loss 0.07094689458608627 1000 model_10 model saved\n",
      "[193 128  37 107  73  39  18   0   0]\n",
      "Training loss 0.013910393230617046 Testing loss 0.06582827866077423 2000 model_10 model saved\n",
      "[195 128  37 107  75  38  18   0   0]\n",
      "Training loss 0.010915132239460945 Testing loss 0.06270255893468857 3000 model_10 model saved\n",
      "[195 130  36 107  77  39  19   0   0]\n",
      "Training loss 0.009280090220272541 Testing loss 0.06167467311024666 4000 model_10 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_11 is training for dataset of 0\n",
      "Model for 11 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[533 393 227 305 164 124  57  28   0]\n",
      "Training loss 0.06882286816835403 Testing loss 0.06447303295135498 0 model_11 model saved\n",
      "[517 484 161 285 283 139 108  26   0]\n",
      "Training loss 0.009712216444313526 Testing loss 0.04824761301279068 1000 model_11 model saved\n",
      "[522 488 157 286 284 144 106  26   0]\n",
      "Training loss 0.0054942406713962555 Testing loss 0.041791368275880814 2000 model_11 model saved\n",
      "[517 487 154 288 280 146 105  27   0]\n",
      "Training loss 0.003825712949037552 Testing loss 0.03896569833159447 3000 model_11 model saved\n",
      "[516 487 154 288 280 148 104  27   0]\n",
      "Training loss 0.002889123745262623 Testing loss 0.03755023702979088 4000 model_11 model saved\n",
      "model_12 is training for dataset of 0\n",
      "Model for 12 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[267 244 125 147  94  64  32   1   0]\n",
      "Training loss 0.07823123037815094 Testing loss 0.0692976638674736 0 model_12 model saved\n",
      "[282 221  74 139 140  64  68  17   0]\n",
      "Training loss 0.01437225379049778 Testing loss 0.0483408197760582 1000 model_12 model saved\n",
      "[275 226  74 140 140  69  70  16   0]\n",
      "Training loss 0.0076625109650194645 Testing loss 0.042617134749889374 2000 model_12 model saved\n",
      "[277 227  75 139 139  71  72  17   0]\n",
      "Training loss 0.005398956593126059 Testing loss 0.04042587801814079 3000 model_12 model saved\n",
      "[281 226  76 138 139  73  72  17   0]\n",
      "Training loss 0.004218098241835833 Testing loss 0.039030127227306366 4000 model_12 model saved\n",
      "model_13 is training for dataset of 0\n",
      "Model for 13 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[595 385 221 305 183 126  87  25   0]\n",
      "Training loss 0.08011668175458908 Testing loss 0.08297650516033173 0 model_13 model saved\n",
      "[579 525 153 309 281 181 114  37   0]\n",
      "Training loss 0.012326386757194996 Testing loss 0.05573263764381409 1000 model_13 model saved\n",
      "[584 521 151 315 283 176 112  37   0]\n",
      "Training loss 0.006643536500632763 Testing loss 0.04860839247703552 2000 model_13 model saved\n",
      "[592 517 154 321 281 175 111  36   0]\n",
      "Training loss 0.0045576198026537895 Testing loss 0.044678106904029846 3000 model_13 model saved\n",
      "[594 512 153 322 279 174 111  36   0]\n",
      "Training loss 0.0034362373407930136 Testing loss 0.042517196387052536 4000 model_13 model saved\n",
      "model_14 is training for dataset of 0\n",
      "Model for 14 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[74 50 28 41 24 22  0  0  0]\n",
      "Training loss 0.08564940094947815 Testing loss 0.09127398580312729 0 model_14 model saved\n",
      "[95 77 13 35 40 21 15  0  0]\n",
      "Training loss 0.03268873319029808 Testing loss 0.07918373495340347 1000 model_14 model saved\n",
      "[94 77 13 35 41 21 14  0  0]\n",
      "Training loss 0.030528943985700607 Testing loss 0.08103006333112717 2000 model_14 model saved\n",
      "[94 77 12 35 41 21 14  0  0]\n",
      "Training loss 0.02970597892999649 Testing loss 0.08195079118013382 3000 model_14 model saved\n",
      "[94 77 13 35 41 21 14  0  0]\n",
      "Training loss 0.02916480414569378 Testing loss 0.08198212832212448 4000 model_14 model saved\n",
      "model_15 is training for dataset of 0\n",
      "Model for 15 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[74 42 21 31 23  0  0  0  0]\n",
      "Training loss 0.09187541902065277 Testing loss 0.08634822815656662 0 model_15 model saved\n",
      "[70 33  0 27 25 18  0  0  0]\n",
      "Training loss 0.039779867976903915 Testing loss 0.05229542404413223 1000 model_15 model saved\n",
      "[72 33  0 27 25 21  0  0  0]\n",
      "Training loss 0.03768804669380188 Testing loss 0.0538964681327343 2000 model_15 model saved\n",
      "[73 33  0 27 26 21  0  0  0]\n",
      "Training loss 0.036918897181749344 Testing loss 0.05449170619249344 3000 model_15 model saved\n",
      "[72 33  0 27 25 21  0  0  0]\n",
      "Training loss 0.03652655705809593 Testing loss 0.05525054410099983 4000 model_15 model saved\n",
      "model_16 is training for dataset of 0\n",
      "Model for 16 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[66 36  0 32  2  1  0  0  0]\n",
      "Training loss 0.06864113360643387 Testing loss 0.05329517275094986 0 model_16 model saved\n",
      "[70 42  0 26 32 19  0  0  0]\n",
      "Training loss 0.04230476915836334 Testing loss 0.053155142813920975 1000 model_16 model saved\n",
      "[71 43  0 26 32 20  0  0  0]\n",
      "Training loss 0.04061461612582207 Testing loss 0.05679012089967728 2000 model_16 model saved\n",
      "[71 43  0 27 32 20  0  0  0]\n",
      "Training loss 0.03994641825556755 Testing loss 0.058500681072473526 3000 model_16 model saved\n",
      "[71 43  0 27 32 19  0  0  0]\n",
      "Training loss 0.03964424505829811 Testing loss 0.05917134881019592 4000 model_16 model saved\n",
      "model_17 is training for dataset of 0\n",
      "Model for 17 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[407 389 224 242 153 105  41  15   0]\n",
      "Training loss 0.07440858334302902 Testing loss 0.0710931047797203 0 model_17 model saved\n",
      "[424 459 151 283 193 129  76  23   0]\n",
      "Training loss 0.010789530351758003 Testing loss 0.04658679664134979 1000 model_17 model saved\n",
      "[427 460 150 291 198 125  75  22   0]\n",
      "Training loss 0.0057638646103441715 Testing loss 0.040505245327949524 2000 model_17 model saved\n",
      "[429 458 150 294 197 126  74  22   0]\n",
      "Training loss 0.004001646302640438 Testing loss 0.038351863622665405 3000 model_17 model saved\n",
      "[430 458 148 294 197 127  75  22   0]\n",
      "Training loss 0.0029607240576297045 Testing loss 0.03711029514670372 4000 model_17 model saved\n",
      "model_18 is training for dataset of 0\n",
      "Model for 18 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[531 437 224 284 169 152  47  26   0]\n",
      "Training loss 0.19766755402088165 Testing loss 0.18598827719688416 0 model_18 model saved\n",
      "[386 302  86 208 163 111  72  23   0]\n",
      "Training loss 0.027884652838110924 Testing loss 0.07661059498786926 1000 model_18 model saved\n",
      "[382 309  84 207 169 108  72  21   0]\n",
      "Training loss 0.01387465838342905 Testing loss 0.06768430769443512 2000 model_18 model saved\n",
      "[382 310  83 207 169 106  69  20   0]\n",
      "Training loss 0.00881736446171999 Testing loss 0.06411745399236679 3000 model_18 model saved\n",
      "[383 311  84 205 171 105  67  20   0]\n",
      "Training loss 0.006395871285349131 Testing loss 0.06253722310066223 4000 model_18 model saved\n",
      "model_19 is training for dataset of 0\n",
      "Model for 19 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[113  86  30  76  31  22  18   1   0]\n",
      "Training loss 0.08852881193161011 Testing loss 0.08082838356494904 0 model_19 model saved\n",
      "[124 114  29  66  66  28  21  16   0]\n",
      "Training loss 0.021546434611082077 Testing loss 0.07356070727109909 1000 model_19 model saved\n",
      "[121 115  29  63  64  28  21  16   0]\n",
      "Training loss 0.016295967623591423 Testing loss 0.07367243617773056 2000 model_19 model saved\n",
      "[122 115  29  62  64  28  21  16   0]\n",
      "Training loss 0.014513459987938404 Testing loss 0.0738847479224205 3000 model_19 model saved\n",
      "[122 115  30  62  63  28  20  16   0]\n",
      "Training loss 0.013585614040493965 Testing loss 0.07366671413183212 4000 model_19 model saved\n",
      "model_20 is training for dataset of 0\n",
      "Model for 20 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[31  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.012116597034037113 Testing loss 0.010803405195474625 0 model_20 model saved\n",
      "[29  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.011964370496571064 Testing loss 0.010072872042655945 1000 model_20 model saved\n",
      "[29  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.011961035430431366 Testing loss 0.010072220116853714 2000 model_20 model saved\n",
      "[29  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.011957806535065174 Testing loss 0.010098678059875965 3000 model_20 model saved\n",
      "[29  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.011954354122281075 Testing loss 0.010096949525177479 4000 model_20 model saved\n",
      "model_21 is training for dataset of 0\n",
      "Model for 21 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63 21 20 27  0  0  0  0  0]\n",
      "Training loss 0.07838710397481918 Testing loss 0.07451744377613068 0 model_21 model saved\n",
      "[43 23  0 23 23  0  0  0  0]\n",
      "Training loss 0.04204137623310089 Testing loss 0.045030154287815094 1000 model_21 model saved\n",
      "[44 23  0 23 23  0  0  0  0]\n",
      "Training loss 0.04135669022798538 Testing loss 0.0453784354031086 2000 model_21 model saved\n",
      "[44 23  0 23 23  0  0  0  0]\n",
      "Training loss 0.04112822934985161 Testing loss 0.045621953904628754 3000 model_21 model saved\n",
      "[44 23  0 23 24  0  0  0  0]\n",
      "Training loss 0.04105876758694649 Testing loss 0.04583841934800148 4000 model_21 model saved\n",
      "model_22 is training for dataset of 0\n",
      "Model for 22 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[28  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.010534708388149738 Testing loss 0.008961292915046215 0 model_22 model saved\n",
      "[27  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.010374060831964016 Testing loss 0.009010070003569126 1000 model_22 model saved\n",
      "[27  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.01037118211388588 Testing loss 0.009015651419758797 2000 model_22 model saved\n",
      "[27  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.010368444956839085 Testing loss 0.009015209041535854 3000 model_22 model saved\n",
      "[27  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.010366871953010559 Testing loss 0.009011577814817429 4000 model_22 model saved\n",
      "model_23 is training for dataset of 0\n",
      "Model for 23 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[179  83  66  80  42  30   0   0   0]\n",
      "Training loss 0.12961919605731964 Testing loss 0.09700442105531693 0 model_23 model saved\n",
      "[190  75  32  72  76  32  23   0   0]\n",
      "Training loss 0.034145232290029526 Testing loss 0.06848276406526566 1000 model_23 model saved\n",
      "[201  72  33  71  75  36  24   0   0]\n",
      "Training loss 0.02339758351445198 Testing loss 0.0714518204331398 2000 model_23 model saved\n",
      "[204  71  33  69  76  36  25   0   0]\n",
      "Training loss 0.02000131644308567 Testing loss 0.07272327691316605 3000 model_23 model saved\n",
      "[204  72  33  68  76  36  25   0   0]\n",
      "Training loss 0.01844548061490059 Testing loss 0.07350746542215347 4000 model_23 model saved\n",
      "model_24 is training for dataset of 0\n",
      "Model for 24 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[235 113  69 106  68  54  26  10  -1]\n",
      "Training loss 0.17641881108283997 Testing loss 0.10263828933238983 0 model_24 model saved\n",
      "[236 117  23  91 104  62  31   0   0]\n",
      "Training loss 0.033577170222997665 Testing loss 0.06548777967691422 1000 model_24 model saved\n",
      "[238 121  25  93 111  63  29   0   0]\n",
      "Training loss 0.019630687311291695 Testing loss 0.06902839988470078 2000 model_24 model saved\n",
      "[240 119  24  94 112  62  30   0   0]\n",
      "Training loss 0.013513308949768543 Testing loss 0.06856793910264969 3000 model_24 model saved\n",
      "[239 116  24  94 111  60  29   0   0]\n",
      "Training loss 0.010508470237255096 Testing loss 0.06747063249349594 4000 model_24 model saved\n",
      "model_25 is training for dataset of 0\n",
      "Model for 25 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[1 0 0 0 0 0 0 0 0]\n",
      "Training loss 0.03250584006309509 Testing loss 0.02649625577032566 0 model_25 model saved\n",
      "[35 18  0  0  0  0  0  0  0]\n",
      "Training loss 0.020603781566023827 Testing loss 0.01797589287161827 1000 model_25 model saved\n",
      "[34 17  0  0  0  0  0  0  0]\n",
      "Training loss 0.020380062982439995 Testing loss 0.018114769831299782 2000 model_25 model saved\n",
      "[35 18  0  0  0  0  0  0  0]\n",
      "Training loss 0.020318465307354927 Testing loss 0.018199041485786438 3000 model_25 model saved\n",
      "[35 18  0  0  0  0  0  0  0]\n",
      "Training loss 0.020293427631258965 Testing loss 0.018174828961491585 4000 model_25 model saved\n",
      "model_26 is training for dataset of 0\n",
      "Model for 26 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[64 25  1 26  1  1  0  0  0]\n",
      "Training loss 0.08765754103660583 Testing loss 0.0810028538107872 0 model_26 model saved\n",
      "[75 38 15 32 33 18  0  0  0]\n",
      "Training loss 0.04581769183278084 Testing loss 0.08019301295280457 1000 model_26 model saved\n",
      "[73 37 15 33 34 18  0  0  0]\n",
      "Training loss 0.042984478175640106 Testing loss 0.0858381986618042 2000 model_26 model saved\n",
      "[72 37 16 33 34 17  0  0  0]\n",
      "Training loss 0.041983820497989655 Testing loss 0.08727538585662842 3000 model_26 model saved\n",
      "[72 37 16 33 33 17  0  0  0]\n",
      "Training loss 0.0415184423327446 Testing loss 0.08820756524801254 4000 model_26 model saved\n",
      "model_27 is training for dataset of 0\n",
      "Model for 27 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[105  54  26  30  25  23   0   0   0]\n",
      "Training loss 0.11590778827667236 Testing loss 0.10930011421442032 0 model_27 model saved\n",
      "[107  65   0  34  42  31  21   0   0]\n",
      "Training loss 0.039200134575366974 Testing loss 0.06354468315839767 1000 model_27 model saved\n",
      "[104  59   0  34  41  29  20   0   0]\n",
      "Training loss 0.03329537436366081 Testing loss 0.06669921427965164 2000 model_27 model saved\n",
      "[103  59   0  34  41  30  20   0   0]\n",
      "Training loss 0.031669970601797104 Testing loss 0.0675068125128746 3000 model_27 model saved\n",
      "[103  60   0  34  41  30  20   0   0]\n",
      "Training loss 0.030773255974054337 Testing loss 0.0684303343296051 4000 model_27 model saved\n",
      "model_28 is training for dataset of 0\n",
      "Model for 28 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[130  44  46  62  40  24   0   0   0]\n",
      "Training loss 0.242414191365242 Testing loss 0.14865902066230774 0 model_28 model saved\n",
      "[123  35   0  39  58  26   0   0   0]\n",
      "Training loss 0.04712590202689171 Testing loss 0.052321795374155045 1000 model_28 model saved\n",
      "[125  37   0  38  60  26   0   0   0]\n",
      "Training loss 0.03930611163377762 Testing loss 0.058107420802116394 2000 model_28 model saved\n",
      "[122  36   0  37  58  25   0   0   0]\n",
      "Training loss 0.03579224646091461 Testing loss 0.06095634028315544 3000 model_28 model saved\n",
      "[119  36   0  36  58  24   0   0   0]\n",
      "Training loss 0.03408403694629669 Testing loss 0.06158372759819031 4000 model_28 model saved\n",
      "model_29 is training for dataset of 0\n",
      "Model for 29 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[153  66  45  66  33  26   1   0   0]\n",
      "Training loss 0.11113052070140839 Testing loss 0.0893317461013794 0 model_29 model saved\n",
      "[177  94  30  64  61  52  26   0   0]\n",
      "Training loss 0.02659016102552414 Testing loss 0.058016322553157806 1000 model_29 model saved\n",
      "[179  92  31  64  62  51  25   0   0]\n",
      "Training loss 0.017252502962946892 Testing loss 0.0584670715034008 2000 model_29 model saved\n",
      "[181  92  31  67  62  49  26   0   0]\n",
      "Training loss 0.01418961863964796 Testing loss 0.05668924003839493 3000 model_29 model saved\n",
      "[180  92  31  65  63  48  26   0   0]\n",
      "Training loss 0.01260324940085411 Testing loss 0.05536608770489693 4000 model_29 model saved\n",
      "model_30 is training for dataset of 0\n",
      "Model for 30 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[201  59  50  90  55  32  17   0   0]\n",
      "Training loss 0.1045413613319397 Testing loss 0.0852428451180458 0 model_30 model saved\n",
      "[219  88  24  80  96  51  35   0   0]\n",
      "Training loss 0.023302603513002396 Testing loss 0.05308890342712402 1000 model_30 model saved\n",
      "[225  88  25  81  97  49  37   0   0]\n",
      "Training loss 0.014918752014636993 Testing loss 0.04782190918922424 2000 model_30 model saved\n",
      "[227  88  26  83  94  49  38   0   0]\n",
      "Training loss 0.011426938697695732 Testing loss 0.045489054173231125 3000 model_30 model saved\n",
      "[228  89  26  85  93  49  38   0   0]\n",
      "Training loss 0.009755541570484638 Testing loss 0.04370110109448433 4000 model_30 model saved\n",
      "model_31 is training for dataset of 0\n",
      "Model for 31 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[86 56 30 43 29 17  0  0  0]\n",
      "Training loss 0.0715237557888031 Testing loss 0.05435001105070114 0 model_31 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82 58 19 48 30 22  0  0  0]\n",
      "Training loss 0.01973761059343815 Testing loss 0.04747142642736435 1000 model_31 model saved\n",
      "[81 56 18 46 30 22  0  0  0]\n",
      "Training loss 0.01757834292948246 Testing loss 0.049786943942308426 2000 model_31 model saved\n",
      "[78 56 18 45 30 21  0  0  0]\n",
      "Training loss 0.01679401844739914 Testing loss 0.05059259384870529 3000 model_31 model saved\n",
      "[78 56 18 44 30 21  0  0  0]\n",
      "Training loss 0.016240978613495827 Testing loss 0.0512596070766449 4000 model_31 model saved\n",
      "model_32 is training for dataset of 0\n",
      "Model for 32 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[74 26 17 33 17  1  0  0  0]\n",
      "Training loss 0.10684186220169067 Testing loss 0.08818105608224869 0 model_32 model saved\n",
      "[65 34  0 33 30 23  0  0  0]\n",
      "Training loss 0.04800071939826012 Testing loss 0.0756874829530716 1000 model_32 model saved\n",
      "[63 33  0 33 30 23  0  0  0]\n",
      "Training loss 0.04516847804188728 Testing loss 0.07932552695274353 2000 model_32 model saved\n",
      "[63 33  0 33 30 23  0  0  0]\n",
      "Training loss 0.04453807696700096 Testing loss 0.08082298189401627 3000 model_32 model saved\n",
      "[63 33  0 33 30 23  0  0  0]\n",
      "Training loss 0.04407414048910141 Testing loss 0.08108867704868317 4000 model_32 model saved\n",
      "model_33 is training for dataset of 0\n",
      "Model for 33 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[77 58 25 47 27 14  0  0  0]\n",
      "Training loss 0.09881047904491425 Testing loss 0.08337847143411636 0 model_33 model saved\n",
      "[68 46 13 32 32 16  0  0  0]\n",
      "Training loss 0.03355931490659714 Testing loss 0.052889540791511536 1000 model_33 model saved\n",
      "[70 47 12 32 32 18  0  0  0]\n",
      "Training loss 0.030740948393940926 Testing loss 0.05477267503738403 2000 model_33 model saved\n",
      "[69 46 13 32 31 18  0  0  0]\n",
      "Training loss 0.029642390087246895 Testing loss 0.055478185415267944 3000 model_33 model saved\n",
      "[69 46 13 32 31 19  0  0  0]\n",
      "Training loss 0.029117075726389885 Testing loss 0.05588714778423309 4000 model_33 model saved\n",
      "model_34 is training for dataset of 0\n",
      "Model for 34 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[125  95  52  63  34  32  19   0   0]\n",
      "Training loss 0.13699519634246826 Testing loss 0.11678547412157059 0 model_34 model saved\n",
      "[118  78  23  47  58  31  21   0   0]\n",
      "Training loss 0.03637607395648956 Testing loss 0.07813964039087296 1000 model_34 model saved\n",
      "[113  79  23  48  58  29  22   0   0]\n",
      "Training loss 0.028437627479434013 Testing loss 0.07518108189105988 2000 model_34 model saved\n",
      "[112  80  24  48  57  29  22   0   0]\n",
      "Training loss 0.025979284197092056 Testing loss 0.07524142414331436 3000 model_34 model saved\n",
      "[111  80  24  48  57  29  22   0   0]\n",
      "Training loss 0.02480132132768631 Testing loss 0.07537098228931427 4000 model_34 model saved\n",
      "model_35 is training for dataset of 0\n",
      "Model for 35 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[104  59  30  52  23  20   1   0   0]\n",
      "Training loss 0.10507884621620178 Testing loss 0.10246122628450394 0 model_35 model saved\n",
      "[108  70  16  32  39  30  18   0   0]\n",
      "Training loss 0.03627349063754082 Testing loss 0.08649281412363052 1000 model_35 model saved\n",
      "[111  69  16  32  37  31  18   0   0]\n",
      "Training loss 0.03118026815354824 Testing loss 0.08988135308027267 2000 model_35 model saved\n",
      "[110  68  16  32  36  31  19   0   0]\n",
      "Training loss 0.02938656695187092 Testing loss 0.08968909829854965 3000 model_35 model saved\n",
      "[111  67  16  32  36  31  20   0   0]\n",
      "Training loss 0.028430916368961334 Testing loss 0.08977352827787399 4000 model_35 model saved\n",
      "model_36 is training for dataset of 0\n",
      "Model for 36 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[404 225 150 240 123  84  26   0   0]\n",
      "Training loss 0.14844824373722076 Testing loss 0.1416752189397812 0 model_36 model saved\n",
      "[442 298  75 204 222 122  62  25   0]\n",
      "Training loss 0.026079440489411354 Testing loss 0.06286735832691193 1000 model_36 model saved\n",
      "[447 303  77 212 221 121  61  25   0]\n",
      "Training loss 0.011751463636755943 Testing loss 0.06095582991838455 2000 model_36 model saved\n",
      "[439 305  77 214 216 119  62  23   0]\n",
      "Training loss 0.007457252126187086 Testing loss 0.05586635321378708 3000 model_36 model saved\n",
      "[433 304  76 213 215 117  62  22   0]\n",
      "Training loss 0.005464153364300728 Testing loss 0.052604902535676956 4000 model_36 model saved\n",
      "model_37 is training for dataset of 0\n",
      "Model for 37 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[157  83  51  78  29  31   1   0   0]\n",
      "Training loss 0.12126382440328598 Testing loss 0.10901999473571777 0 model_37 model saved\n",
      "[171 113  33  73  68  39  22   0   0]\n",
      "Training loss 0.027752961963415146 Testing loss 0.08420678228139877 1000 model_37 model saved\n",
      "[169 114  33  75  65  37  20   0   0]\n",
      "Training loss 0.02113989368081093 Testing loss 0.08184413611888885 2000 model_37 model saved\n",
      "[169 116  34  75  64  37  21   0   0]\n",
      "Training loss 0.019070956856012344 Testing loss 0.08215143531560898 3000 model_37 model saved\n",
      "[167 117  34  75  63  37  21   0   0]\n",
      "Training loss 0.01788421906530857 Testing loss 0.08321136981248856 4000 model_37 model saved\n",
      "model_38 is training for dataset of 0\n",
      "Model for 38 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[137 115  64  81  35  24   2   0   0]\n",
      "Training loss 0.10372651368379593 Testing loss 0.10049713402986526 0 model_38 model saved\n",
      "[122  99  13  72  71  34  21   0   0]\n",
      "Training loss 0.026539336889982224 Testing loss 0.06584630161523819 1000 model_38 model saved\n",
      "[129  96  15  74  74  31  20   0   0]\n",
      "Training loss 0.019205592572689056 Testing loss 0.06782958656549454 2000 model_38 model saved\n",
      "[131  97  16  75  75  29  20   0   0]\n",
      "Training loss 0.016497254371643066 Testing loss 0.06690613925457001 3000 model_38 model saved\n",
      "[131  98  16  77  75  29  20   0   0]\n",
      "Training loss 0.015086081810295582 Testing loss 0.06581010669469833 4000 model_38 model saved\n",
      "model_39 is training for dataset of 0\n",
      "Model for 39 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[98 61 31 38 25 18  0  0  0]\n",
      "Training loss 0.0800497755408287 Testing loss 0.06684091687202454 0 model_39 model saved\n",
      "[102  64  20  37  32  25   0   0   0]\n",
      "Training loss 0.03305010870099068 Testing loss 0.061263926327228546 1000 model_39 model saved\n",
      "[101  65  19  37  34  24   0   0   0]\n",
      "Training loss 0.03129713237285614 Testing loss 0.061128757894039154 2000 model_39 model saved\n",
      "[101  63  18  37  34  24   0   0   0]\n",
      "Training loss 0.030623124912381172 Testing loss 0.06153035908937454 3000 model_39 model saved\n",
      "[102  64  19  37  34  23   0   0   0]\n",
      "Training loss 0.030268259346485138 Testing loss 0.06170717999339104 4000 model_39 model saved\n",
      "model_40 is training for dataset of 0\n",
      "Model for 40 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[249 176 103 135  76  60  35  10   0]\n",
      "Training loss 0.09330359101295471 Testing loss 0.0832657516002655 0 model_40 model saved\n",
      "[219 155  53 109  95  56  33  18   0]\n",
      "Training loss 0.015205960720777512 Testing loss 0.05984264612197876 1000 model_40 model saved\n",
      "[220 165  54 108 100  58  31  19   0]\n",
      "Training loss 0.008991011418402195 Testing loss 0.05334363505244255 2000 model_40 model saved\n",
      "[222 165  56 110 101  58  30  18   0]\n",
      "Training loss 0.006662718020379543 Testing loss 0.04958965629339218 3000 model_40 model saved\n",
      "[223 165  56 110 101  59  30  19   0]\n",
      "Training loss 0.005434805992990732 Testing loss 0.04762024059891701 4000 model_40 model saved\n",
      "model_41 is training for dataset of 0\n",
      "Model for 41 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[86 63 29 37 26 23  1  0  0]\n",
      "Training loss 0.08924619853496552 Testing loss 0.0870232805609703 0 model_41 model saved\n",
      "[98 63 13 38 33 20 18  0  0]\n",
      "Training loss 0.03324156999588013 Testing loss 0.06534916162490845 1000 model_41 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98 62 12 38 33 21 18  0  0]\n",
      "Training loss 0.030481837689876556 Testing loss 0.06397031247615814 2000 model_41 model saved\n",
      "[98 61 12 38 32 21 18  0  0]\n",
      "Training loss 0.029487930238246918 Testing loss 0.0639495849609375 3000 model_41 model saved\n",
      "[98 61 12 38 32 21 18  0  0]\n",
      "Training loss 0.028886055573821068 Testing loss 0.06424275040626526 4000 model_41 model saved\n",
      "model_42 is training for dataset of 0\n",
      "Model for 42 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[170 142  81  99  36  34  20   1   0]\n",
      "Training loss 0.07296252250671387 Testing loss 0.06588174402713776 0 model_42 model saved\n",
      "[192 164  55 103  83  55  29  13   0]\n",
      "Training loss 0.01395464688539505 Testing loss 0.04924739897251129 1000 model_42 model saved\n",
      "[189 164  55 102  84  54  29  13   0]\n",
      "Training loss 0.00884715374559164 Testing loss 0.04616740718483925 2000 model_42 model saved\n",
      "[188 165  56 100  86  54  29  14   0]\n",
      "Training loss 0.006922424770891666 Testing loss 0.04422062635421753 3000 model_42 model saved\n",
      "[189 164  55  99  87  54  29  14   0]\n",
      "Training loss 0.00593558419495821 Testing loss 0.04315314441919327 4000 model_42 model saved\n",
      "model_43 is training for dataset of 0\n",
      "Model for 43 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[518 316 215 267 129  99  66  21   0]\n",
      "Training loss 0.06629789620637894 Testing loss 0.05715028569102287 0 model_43 model saved\n",
      "[461 292 131 259 160  82  59  27   0]\n",
      "Training loss 0.00933897402137518 Testing loss 0.032569896429777145 1000 model_43 model saved\n",
      "[459 290 127 259 158  87  57  28   0]\n",
      "Training loss 0.0053508165292441845 Testing loss 0.02857716754078865 2000 model_43 model saved\n",
      "[453 286 126 256 157  88  57  29   0]\n",
      "Training loss 0.0036751418374478817 Testing loss 0.026991525664925575 3000 model_43 model saved\n",
      "[456 285 125 255 160  89  58  29   0]\n",
      "Training loss 0.002730929059907794 Testing loss 0.026258256286382675 4000 model_43 model saved\n",
      "model_44 is training for dataset of 0\n",
      "Model for 44 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[227 150  91 112  80  39  27   2   0]\n",
      "Training loss 0.08303771913051605 Testing loss 0.07398095726966858 0 model_44 model saved\n",
      "[254 204  63 137 113  47  31  15   0]\n",
      "Training loss 0.013998347334563732 Testing loss 0.05210157856345177 1000 model_44 model saved\n",
      "[253 208  64 143 112  49  31  14   0]\n",
      "Training loss 0.008162464946508408 Testing loss 0.04675326123833656 2000 model_44 model saved\n",
      "[250 207  63 145 111  48  30  14   0]\n",
      "Training loss 0.006112425588071346 Testing loss 0.044442132115364075 3000 model_44 model saved\n",
      "[247 207  62 145 112  49  31  14   0]\n",
      "Training loss 0.004884451162070036 Testing loss 0.04324479401111603 4000 model_44 model saved\n",
      "model_45 is training for dataset of 0\n",
      "Model for 45 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[90 72 28 33 26 30  1  0  0]\n",
      "Training loss 0.09233852475881577 Testing loss 0.09106522798538208 0 model_45 model saved\n",
      "[96 71 23 64 34 27 16  0  0]\n",
      "Training loss 0.02950858324766159 Testing loss 0.06994694471359253 1000 model_45 model saved\n",
      "[98 71 22 64 35 26 17  0  0]\n",
      "Training loss 0.026104608550667763 Testing loss 0.07204518467187881 2000 model_45 model saved\n",
      "[99 71 22 63 35 26 17  0  0]\n",
      "Training loss 0.024921050295233727 Testing loss 0.07403485476970673 3000 model_45 model saved\n",
      "[100  71  22  64  36  26  17   0   0]\n",
      "Training loss 0.02413637563586235 Testing loss 0.07489567250013351 4000 model_45 model saved\n",
      "model_46 is training for dataset of 0\n",
      "Model for 46 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[59 45 29 38 22  1  0  0  0]\n",
      "Training loss 0.07392331957817078 Testing loss 0.053600117564201355 0 model_46 model saved\n",
      "[68 75 22 40 29 14 14  0  0]\n",
      "Training loss 0.02303607575595379 Testing loss 0.054325927048921585 1000 model_46 model saved\n",
      "[67 72 22 38 29 15 13  0  0]\n",
      "Training loss 0.0195660088211298 Testing loss 0.05446759983897209 2000 model_46 model saved\n",
      "[67 72 22 38 30 15 13  0  0]\n",
      "Training loss 0.018278909847140312 Testing loss 0.05488975718617439 3000 model_46 model saved\n",
      "[67 72 22 36 30 15 13  0  0]\n",
      "Training loss 0.017514491453766823 Testing loss 0.055252984166145325 4000 model_46 model saved\n",
      "model_47 is training for dataset of 0\n",
      "Model for 47 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[ 1 20  1  1  0  0  0  0  0]\n",
      "Training loss 0.037157297134399414 Testing loss 0.013176378794014454 0 model_47 model saved\n",
      "[14 11 10  8  0  0  0  0  0]\n",
      "Training loss 0.025348659604787827 Testing loss 0.01264189463108778 1000 model_47 model saved\n",
      "[13 10 10  8  0  0  0  0  0]\n",
      "Training loss 0.02480437234044075 Testing loss 0.012595432810485363 2000 model_47 model saved\n",
      "[13 10 10  8  0  0  0  0  0]\n",
      "Training loss 0.024633752182126045 Testing loss 0.012607578188180923 3000 model_47 model saved\n",
      "[13 10 10  8  0  0  0  0  0]\n",
      "Training loss 0.024592293426394463 Testing loss 0.012593639083206654 4000 model_47 model saved\n",
      "model_48 is training for dataset of 0\n",
      "Model for 48 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[133  93  55  62  35  26  16   0   0]\n",
      "Training loss 0.0574546679854393 Testing loss 0.04308047518134117 0 model_48 model saved\n",
      "[124  75  42  72  37  21  10   0   0]\n",
      "Training loss 0.012764183804392815 Testing loss 0.02500462345778942 1000 model_48 model saved\n",
      "[128  78  43  75  38  21   9   0   0]\n",
      "Training loss 0.01033096294850111 Testing loss 0.02466624602675438 2000 model_48 model saved\n",
      "[131  79  44  77  40  20   8   0   0]\n",
      "Training loss 0.009315096773207188 Testing loss 0.02468855492770672 3000 model_48 model saved\n",
      "[132  82  45  78  40  19   8   0   0]\n",
      "Training loss 0.008713526651263237 Testing loss 0.024901505559682846 4000 model_48 model saved\n",
      "model_49 is training for dataset of 0\n",
      "Model for 49 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[66 69 34 29 20  1  0  0  0]\n",
      "Training loss 0.06162793189287186 Testing loss 0.037773121148347855 0 model_49 model saved\n",
      "[54 55 19 49 17 10  0  0  0]\n",
      "Training loss 0.02133682742714882 Testing loss 0.04016110301017761 1000 model_49 model saved\n",
      "[57 56 19 50 18 10  0  0  0]\n",
      "Training loss 0.018295401707291603 Testing loss 0.04154282063245773 2000 model_49 model saved\n",
      "[57 56 19 50 19  9  0  0  0]\n",
      "Training loss 0.017155993729829788 Testing loss 0.0426306314766407 3000 model_49 model saved\n",
      "[58 57 19 51 19  9  0  0  0]\n",
      "Training loss 0.016563626006245613 Testing loss 0.043504174798727036 4000 model_49 model saved\n",
      "model_50 is training for dataset of 0\n",
      "Model for 50 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[43 22 19 19  1  0  0  0  0]\n",
      "Training loss 0.05316806584596634 Testing loss 0.02671155333518982 0 model_50 model saved\n",
      "[35 20 11 22 11  0  0  0  0]\n",
      "Training loss 0.02947799116373062 Testing loss 0.02850773185491562 1000 model_50 model saved\n",
      "[36 21 11 23 12  0  0  0  0]\n",
      "Training loss 0.027834556996822357 Testing loss 0.029548153281211853 2000 model_50 model saved\n",
      "[35 21 12 23 12  0  0  0  0]\n",
      "Training loss 0.027277976274490356 Testing loss 0.03002197854220867 3000 model_50 model saved\n",
      "[36 21 12 23 13  0  0  0  0]\n",
      "Training loss 0.02701893262565136 Testing loss 0.03022303804755211 4000 model_50 model saved\n",
      "model_51 is training for dataset of 0\n",
      "Model for 51 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[775 618 395 485 267 163  45  20   0]\n",
      "Training loss 0.04866481572389603 Testing loss 0.024374613538384438 0 model_51 model saved\n",
      "[508 590 260 303 273 167  96  33   0]\n",
      "Training loss 0.009300503879785538 Testing loss 0.014527938328683376 1000 model_51 model saved\n",
      "[531 562 259 304 267 151 100  34   0]\n",
      "Training loss 0.0060280864126980305 Testing loss 0.013133630156517029 2000 model_51 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[535 564 255 305 272 143  98  33   0]\n",
      "Training loss 0.004790561273694038 Testing loss 0.011895531788468361 3000 model_51 model saved\n",
      "[532 574 254 311 281 140  96  34   0]\n",
      "Training loss 0.004054654389619827 Testing loss 0.011270293965935707 4000 model_51 model saved\n",
      "model_52 is training for dataset of 0\n",
      "Model for 52 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[138 135  91  96  39  25   1   1   0]\n",
      "Training loss 0.10736436396837234 Testing loss 0.09368639439344406 0 model_52 model saved\n",
      "[109 116  35  86  46  20  10   0   0]\n",
      "Training loss 0.022592579945921898 Testing loss 0.04149530827999115 1000 model_52 model saved\n",
      "[105 111  36  89  42  16  11   0   0]\n",
      "Training loss 0.01428926270455122 Testing loss 0.042353350669145584 2000 model_52 model saved\n",
      "[103 110  36  93  41  15  12   0   0]\n",
      "Training loss 0.011587045155465603 Testing loss 0.04335346445441246 3000 model_52 model saved\n",
      "[103 109  36  94  41  15  12   0   0]\n",
      "Training loss 0.01019684411585331 Testing loss 0.043621726334095 4000 model_52 model saved\n",
      "model_53 is training for dataset of 0\n",
      "Model for 53 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[160 144  89  73  49  29   2   0   0]\n",
      "Training loss 0.06518197059631348 Testing loss 0.034170717000961304 0 model_53 model saved\n",
      "[167 187  56 125  81  43  30   0   0]\n",
      "Training loss 0.01461456622928381 Testing loss 0.028399258852005005 1000 model_53 model saved\n",
      "[154 188  54 125  76  43  30   0   0]\n",
      "Training loss 0.008221828378736973 Testing loss 0.027437523007392883 2000 model_53 model saved\n",
      "[154 186  53 123  74  47  28   0   0]\n",
      "Training loss 0.005864409264177084 Testing loss 0.027616485953330994 3000 model_53 model saved\n",
      "[155 183  53 120  72  50  27   0   0]\n",
      "Training loss 0.0045637222938239574 Testing loss 0.027399186044931412 4000 model_53 model saved\n",
      "model_54 is training for dataset of 0\n",
      "Model for 54 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[160 157  77  78  34  32  20   0   0]\n",
      "Training loss 0.07794977724552155 Testing loss 0.053916189819574356 0 model_54 model saved\n",
      "[130 187  55 106  73  29  29   0   0]\n",
      "Training loss 0.01463100966066122 Testing loss 0.04736342281103134 1000 model_54 model saved\n",
      "[128 200  60 105  75  29  28   0   0]\n",
      "Training loss 0.00953812338411808 Testing loss 0.0450088307261467 2000 model_54 model saved\n",
      "[129 203  61 105  74  28  28   0   0]\n",
      "Training loss 0.007642123848199844 Testing loss 0.0435384102165699 3000 model_54 model saved\n",
      "[128 201  60 103  73  28  28   0   0]\n",
      "Training loss 0.006514519918709993 Testing loss 0.04269852861762047 4000 model_54 model saved\n",
      "model_55 is training for dataset of 0\n",
      "Model for 55 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[38 39 28 29  2  0  0  0  0]\n",
      "Training loss 0.062329456210136414 Testing loss 0.03163633123040199 0 model_55 model saved\n",
      "[53 67 22 38 30  0  0  0  0]\n",
      "Training loss 0.032257549464702606 Testing loss 0.035019949078559875 1000 model_55 model saved\n",
      "[55 65 20 39 30  0  0  0  0]\n",
      "Training loss 0.029150420799851418 Testing loss 0.03597447648644447 2000 model_55 model saved\n",
      "[55 66 19 40 29  0  0  0  0]\n",
      "Training loss 0.028065171092748642 Testing loss 0.036599595099687576 3000 model_55 model saved\n",
      "[55 66 20 40 29  0  0  0  0]\n",
      "Training loss 0.027511892840266228 Testing loss 0.03717103227972984 4000 model_55 model saved\n",
      "model_56 is training for dataset of 0\n",
      "Model for 56 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[85 90 41 43 28  2  1  0  0]\n",
      "Training loss 0.08145447820425034 Testing loss 0.043695200234651566 0 model_56 model saved\n",
      "[ 72 124  32  64  45  29  14   0   0]\n",
      "Training loss 0.02237403206527233 Testing loss 0.04342581331729889 1000 model_56 model saved\n",
      "[ 69 123  32  63  48  28  13   0   0]\n",
      "Training loss 0.015749860554933548 Testing loss 0.04642292857170105 2000 model_56 model saved\n",
      "[ 67 121  32  62  48  28  14   0   0]\n",
      "Training loss 0.013604878447949886 Testing loss 0.0470433235168457 3000 model_56 model saved\n",
      "[ 68 119  32  63  50  28  14   0   0]\n",
      "Training loss 0.012379838153719902 Testing loss 0.04723787307739258 4000 model_56 model saved\n",
      "model_57 is training for dataset of 0\n",
      "Model for 57 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[75 40 31 29 21  1  0  0  0]\n",
      "Training loss 0.0716182142496109 Testing loss 0.027591874822974205 0 model_57 model saved\n",
      "[46 57 14 31 20 11 11 -1  0]\n",
      "Training loss 0.023083774372935295 Testing loss 0.028792819008231163 1000 model_57 model saved\n",
      "[47 57 15 32 19 12 10  0  0]\n",
      "Training loss 0.01855151355266571 Testing loss 0.02948453649878502 2000 model_57 model saved\n",
      "[48 59 16 33 19 13 10  0  0]\n",
      "Training loss 0.016960421577095985 Testing loss 0.02996658906340599 3000 model_57 model saved\n",
      "[48 60 16 34 19 13 10  0  0]\n",
      "Training loss 0.01614135317504406 Testing loss 0.02995932474732399 4000 model_57 model saved\n",
      "model_58 is training for dataset of 0\n",
      "Model for 58 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[23 20  0  0  0  0  0  0  0]\n",
      "Training loss 0.019743047654628754 Testing loss 0.009833084419369698 0 model_58 model saved\n",
      "[23 20  0  0  0  0  0  0  0]\n",
      "Training loss 0.01973658986389637 Testing loss 0.00962655059993267 1000 model_58 model saved\n",
      "[23 20  0  0  0  0  0  0  0]\n",
      "Training loss 0.019727854058146477 Testing loss 0.00966214295476675 2000 model_58 model saved\n",
      "[23 20  0  0  0  0  0  0  0]\n",
      "Training loss 0.01972036249935627 Testing loss 0.009690429084002972 3000 model_58 model saved\n",
      "[23 20  0  0  0  0  0  0  0]\n",
      "Training loss 0.01972290500998497 Testing loss 0.009676503017544746 4000 model_58 model saved\n",
      "model_59 is training for dataset of 0\n",
      "Model for 59 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[38 31 21 22  1  0  0  0  0]\n",
      "Training loss 0.05562899261713028 Testing loss 0.023466220125555992 0 model_59 model saved\n",
      "[37 30 22 19 13  0  0  0  0]\n",
      "Training loss 0.03339254483580589 Testing loss 0.025472480803728104 1000 model_59 model saved\n",
      "[38 30 21 20 13  0  0  0  0]\n",
      "Training loss 0.03172652795910835 Testing loss 0.025117723271250725 2000 model_59 model saved\n",
      "[38 31 21 21 13  0  0  0  0]\n",
      "Training loss 0.031137220561504364 Testing loss 0.025200307369232178 3000 model_59 model saved\n",
      "[39 31 21 21 13  0  0  0  0]\n",
      "Training loss 0.03083229809999466 Testing loss 0.025250308215618134 4000 model_59 model saved\n",
      "model_60 is training for dataset of 0\n",
      "Model for 60 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[47 59 32 31 18  1  0  0  0]\n",
      "Training loss 0.0652540996670723 Testing loss 0.0428149439394474 0 model_60 model saved\n",
      "[57 53 24 44 15 11  0  0  0]\n",
      "Training loss 0.024677956476807594 Testing loss 0.03682262450456619 1000 model_60 model saved\n",
      "[57 54 24 43 16 11  0  0  0]\n",
      "Training loss 0.021825173869729042 Testing loss 0.03803960978984833 2000 model_60 model saved\n",
      "[57 54 24 43 16 11  0  0  0]\n",
      "Training loss 0.020849943161010742 Testing loss 0.03891364485025406 3000 model_60 model saved\n",
      "[57 53 24 42 17 11  0  0  0]\n",
      "Training loss 0.020201947540044785 Testing loss 0.0394861176609993 4000 model_60 model saved\n",
      "model_61 is training for dataset of 0\n",
      "Model for 61 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[ 0  0  1  0  0  0 -1  0  0]\n",
      "Training loss 0.00019059955957345665 Testing loss 4.1219314880436286e-05 0 model_61 model saved\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "Training loss 3.399113120394759e-05 Testing loss 7.549920724159165e-07 1000 model_61 model saved\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "Training loss 1.2418877304298803e-05 Testing loss 4.6883812387932267e-07 2000 model_61 model saved\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "Training loss 6.218606358743273e-06 Testing loss 1.7297230670010322e-07 3000 model_61 model saved\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "Training loss 3.7080462789162993e-06 Testing loss 8.044340660262606e-08 4000 model_61 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_62 is training for dataset of 0\n",
      "Model for 62 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[27  0 -1  0 -1  0  0 -1  0]\n",
      "Training loss 0.012417580001056194 Testing loss 0.006157678551971912 0 model_62 model saved\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.012182462960481644 Testing loss 0.00585213303565979 1000 model_62 model saved\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.01214054599404335 Testing loss 0.005790153983980417 2000 model_62 model saved\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.012126564979553223 Testing loss 0.005711536388844252 3000 model_62 model saved\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.012111449614167213 Testing loss 0.005736041814088821 4000 model_62 model saved\n",
      "model_63 is training for dataset of 0\n",
      "Model for 63 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[120 116  68  75  47  26  14   0   0]\n",
      "Training loss 0.03827124834060669 Testing loss 0.03509989380836487 0 model_63 model saved\n",
      "[115 104  62  68  41  29  13   0   0]\n",
      "Training loss 0.023440666496753693 Testing loss 0.03774919733405113 1000 model_63 model saved\n",
      "[121 110  69  72  40  29  15   0   0]\n",
      "Training loss 0.016105683520436287 Testing loss 0.03499016910791397 2000 model_63 model saved\n",
      "[120 110  67  71  40  29  16   0   0]\n",
      "Training loss 0.012909210287034512 Testing loss 0.033154554665088654 3000 model_63 model saved\n",
      "[125 113  69  71  41  30  17   0   0]\n",
      "Training loss 0.011243447661399841 Testing loss 0.03232506662607193 4000 model_63 model saved\n",
      "model_1 is training for dataset of 1\n",
      "Model for 1 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[124 118  16  60  82  37  26   0   0]\n",
      "Training loss 0.0765017420053482 Testing loss 0.06125422567129135 0 model_1 model saved\n",
      "[103  69  36  66  31  17   0   0   0]\n",
      "Training loss 0.02199825644493103 Testing loss 0.03168058022856712 1000 model_1 model saved\n",
      "[103  70  36  66  32  18   0   0   0]\n",
      "Training loss 0.02097250148653984 Testing loss 0.031576335430145264 2000 model_1 model saved\n",
      "[101  69  36  64  32  17   0   0   0]\n",
      "Training loss 0.020405573770403862 Testing loss 0.03233040124177933 3000 model_1 model saved\n",
      "[103  68  35  64  32  17   0   0   0]\n",
      "Training loss 0.02010752260684967 Testing loss 0.03273671492934227 4000 model_1 model saved\n",
      "model_2 is training for dataset of 1\n",
      "Model for 2 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[285 182  67 129 121  69  29   0   0]\n",
      "Training loss 0.08067170530557632 Testing loss 0.06991244852542877 0 model_2 model saved\n",
      "[188 128  93  95  65  55  10   0   0]\n",
      "Training loss 0.010985884815454483 Testing loss 0.036335356533527374 1000 model_2 model saved\n",
      "[185 131  91  98  66  54  10   0   0]\n",
      "Training loss 0.008839300833642483 Testing loss 0.03481535241007805 2000 model_2 model saved\n",
      "[182 132  89 100  67  52  11   0   0]\n",
      "Training loss 0.007862953469157219 Testing loss 0.03393131494522095 3000 model_2 model saved\n",
      "[181 134  90 102  68  52  10   0   0]\n",
      "Training loss 0.007187907584011555 Testing loss 0.033983804285526276 4000 model_2 model saved\n",
      "model_3 is training for dataset of 1\n",
      "Model for 3 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[192 104  20  75  75  63  30   0   0]\n",
      "Training loss 0.14239655435085297 Testing loss 0.10078992694616318 0 model_3 model saved\n",
      "[191 109  69  95  67  29  16   0   0]\n",
      "Training loss 0.021797217428684235 Testing loss 0.06508175283670425 1000 model_3 model saved\n",
      "[190 111  67  94  69  30  16   0   0]\n",
      "Training loss 0.019273903220891953 Testing loss 0.06286878138780594 2000 model_3 model saved\n",
      "[191 112  67  96  70  31  16   0   0]\n",
      "Training loss 0.017926301807165146 Testing loss 0.06335281580686569 3000 model_3 model saved\n",
      "[189 110  66  95  69  31  16   0   0]\n",
      "Training loss 0.017090419307351112 Testing loss 0.06320904940366745 4000 model_3 model saved\n",
      "model_4 is training for dataset of 1\n",
      "Model for 4 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[127  70  26  55  59  32  17   0   0]\n",
      "Training loss 0.08340593427419662 Testing loss 0.06996849179267883 0 model_4 model saved\n",
      "[90 50 26 51 32 15  1  0  0]\n",
      "Training loss 0.0244502741843462 Testing loss 0.03848947957158089 1000 model_4 model saved\n",
      "[90 50 25 52 33 16  0  0  0]\n",
      "Training loss 0.023293111473321915 Testing loss 0.03954554721713066 2000 model_4 model saved\n",
      "[89 50 25 51 33 16  0  0  0]\n",
      "Training loss 0.022734029218554497 Testing loss 0.040403813123703 3000 model_4 model saved\n",
      "[88 50 25 51 33 17  0  0  0]\n",
      "Training loss 0.022336089983582497 Testing loss 0.04147149994969368 4000 model_4 model saved\n",
      "model_5 is training for dataset of 1\n",
      "Model for 5 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[95 77 22 50 50 24  0  0  0]\n",
      "Training loss 0.06684928387403488 Testing loss 0.04738692566752434 0 model_5 model saved\n",
      "[94 73 31 66 26 19  0  0  0]\n",
      "Training loss 0.020687313750386238 Testing loss 0.03187739849090576 1000 model_5 model saved\n",
      "[94 73 31 66 25 19  0  0  0]\n",
      "Training loss 0.019736913964152336 Testing loss 0.032378267496824265 2000 model_5 model saved\n",
      "[94 73 30 65 24 19  0  0  0]\n",
      "Training loss 0.019246194511651993 Testing loss 0.03234478831291199 3000 model_5 model saved\n",
      "[95 73 30 65 25 19  0  0  0]\n",
      "Training loss 0.01897052675485611 Testing loss 0.03245329111814499 4000 model_5 model saved\n",
      "model_6 is training for dataset of 1\n",
      "Model for 6 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[217 206  64 115 126  48  26  13   0]\n",
      "Training loss 0.05026360973715782 Testing loss 0.03092566505074501 0 model_6 model saved\n",
      "[169 179 105  90  74  42  19   1   0]\n",
      "Training loss 0.005227391608059406 Testing loss 0.017337342724204063 1000 model_6 model saved\n",
      "[170 175 101 100  72  43  19   1   0]\n",
      "Training loss 0.003528886940330267 Testing loss 0.018721047788858414 2000 model_6 model saved\n",
      "[167 170  99 103  71  44  20   1   0]\n",
      "Training loss 0.002736027119681239 Testing loss 0.019566455855965614 3000 model_6 model saved\n",
      "[164 169  97 105  72  44  22   1   0]\n",
      "Training loss 0.002283701440319419 Testing loss 0.01945502497255802 4000 model_6 model saved\n",
      "model_7 is training for dataset of 1\n",
      "Model for 7 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[396 299  73 182 208 120  86  21   0]\n",
      "Training loss 0.16444355249404907 Testing loss 0.09559377282857895 0 model_7 model saved\n",
      "[361 259 169 170 136  90  50  15   0]\n",
      "Training loss 0.0106035266071558 Testing loss 0.05729180946946144 1000 model_7 model saved\n",
      "[357 251 165 168 131  90  51  15   0]\n",
      "Training loss 0.007154023740440607 Testing loss 0.05185950919985771 2000 model_7 model saved\n",
      "[355 246 164 166 128  90  51  16   0]\n",
      "Training loss 0.0054883225820958614 Testing loss 0.04849214106798172 3000 model_7 model saved\n",
      "[353 244 161 166 123  89  50  16   0]\n",
      "Training loss 0.0044669765047729015 Testing loss 0.04637051373720169 4000 model_7 model saved\n",
      "model_8 is training for dataset of 1\n",
      "Model for 8 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[209 131  34 101  83  53  27   1   0]\n",
      "Training loss 0.25462421774864197 Testing loss 0.0870313048362732 0 model_8 model saved\n",
      "[201 140  61 110  66  48  28  12   0]\n",
      "Training loss 0.01771281100809574 Testing loss 0.06780797988176346 1000 model_8 model saved\n",
      "[200 136  60 111  65  50  26  12   0]\n",
      "Training loss 0.012614329345524311 Testing loss 0.06636755913496017 2000 model_8 model saved\n",
      "[201 137  60 111  64  51  25  12   0]\n",
      "Training loss 0.010137424804270267 Testing loss 0.06704931706190109 3000 model_8 model saved\n",
      "[202 137  61 111  63  52  24  12   0]\n",
      "Training loss 0.008410092443227768 Testing loss 0.06716456264257431 4000 model_8 model saved\n",
      "model_9 is training for dataset of 1\n",
      "Model for 9 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[393 284  84 222 168  76  79  22   0]\n",
      "Training loss 0.11788398027420044 Testing loss 0.09642855823040009 0 model_9 model saved\n",
      "[354 232 153 180  81  77  60  19   0]\n",
      "Training loss 0.00881887972354889 Testing loss 0.05778869241476059 1000 model_9 model saved\n",
      "[352 226 153 177  80  77  59  19   0]\n",
      "Training loss 0.006022571120411158 Testing loss 0.0536530427634716 2000 model_9 model saved\n",
      "[353 224 153 176  81  77  59  19   0]\n",
      "Training loss 0.004729794338345528 Testing loss 0.05111796408891678 3000 model_9 model saved\n",
      "[354 224 153 176  82  77  59  19   0]\n",
      "Training loss 0.003918189089745283 Testing loss 0.04968380182981491 4000 model_9 model saved\n",
      "model_10 is training for dataset of 1\n",
      "Model for 10 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[199 133  36 100  88  30  27   0   0]\n",
      "Training loss 0.12635290622711182 Testing loss 0.08340492099523544 0 model_10 model saved\n",
      "[181 116  82  83  39  29  19   0   0]\n",
      "Training loss 0.01942743919789791 Testing loss 0.05889039486646652 1000 model_10 model saved\n",
      "[181 111  84  84  36  27  20   0   0]\n",
      "Training loss 0.016917850822210312 Testing loss 0.059064000844955444 2000 model_10 model saved\n",
      "[181 111  85  84  36  27  20   0   0]\n",
      "Training loss 0.015684062615036964 Testing loss 0.05988181754946709 3000 model_10 model saved\n",
      "[180 110  85  83  37  27  20   0   0]\n",
      "Training loss 0.014886564575135708 Testing loss 0.059738535434007645 4000 model_10 model saved\n",
      "model_11 is training for dataset of 1\n",
      "Model for 11 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[529 495 176 289 241 162  91  41   0]\n",
      "Training loss 0.05600564181804657 Testing loss 0.06714261323213577 0 model_11 model saved\n",
      "[434 354 179 256 142  92  57  20   0]\n",
      "Training loss 0.004262520000338554 Testing loss 0.02806660160422325 1000 model_11 model saved\n",
      "[431 358 180 259 145  92  60  20   0]\n",
      "Training loss 0.002719707554206252 Testing loss 0.025998737663030624 2000 model_11 model saved\n",
      "[430 363 181 260 148  92  60  20   0]\n",
      "Training loss 0.0020194801036268473 Testing loss 0.02457304857671261 3000 model_11 model saved\n",
      "[426 363 182 257 147  93  60  20   0]\n",
      "Training loss 0.0015466492623090744 Testing loss 0.023446979001164436 4000 model_11 model saved\n",
      "model_12 is training for dataset of 1\n",
      "Model for 12 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[238 228  74 142 118  64  74   9   0]\n",
      "Training loss 0.06884972006082535 Testing loss 0.05927460640668869 0 model_12 model saved\n",
      "[241 216 123 133  74  62  26  -2   0]\n",
      "Training loss 0.006449950393289328 Testing loss 0.035089991986751556 1000 model_12 model saved\n",
      "[243 215 122 133  75  60  25  -1   0]\n",
      "Training loss 0.004500748123973608 Testing loss 0.03293640911579132 2000 model_12 model saved\n",
      "[242 215 121 134  76  59  25  -1   0]\n",
      "Training loss 0.0036402561236172915 Testing loss 0.03216986358165741 3000 model_12 model saved\n",
      "[243 215 120 135  76  59  24   0   0]\n",
      "Training loss 0.0031081789638847113 Testing loss 0.03172760829329491 4000 model_12 model saved\n",
      "model_13 is training for dataset of 1\n",
      "Model for 13 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[408 434 142 280 237 117  45  31   0]\n",
      "Training loss 0.06820305436849594 Testing loss 0.05126117914915085 0 model_13 model saved\n",
      "[357 261 175 183 106  84  47  23   0]\n",
      "Training loss 0.0060629695653915405 Testing loss 0.024275679141283035 1000 model_13 model saved\n",
      "[348 262 172 183 104  80  45  22   0]\n",
      "Training loss 0.003879664931446314 Testing loss 0.0221883412450552 2000 model_13 model saved\n",
      "[352 266 172 185 106  84  45  21   0]\n",
      "Training loss 0.0028526114765554667 Testing loss 0.021242091432213783 3000 model_13 model saved\n",
      "[351 266 171 185 108  83  46  21   0]\n",
      "Training loss 0.00227169506251812 Testing loss 0.020317593589425087 4000 model_13 model saved\n",
      "model_14 is training for dataset of 1\n",
      "Model for 14 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[72 63 16 35 35 15 17  0  0]\n",
      "Training loss 0.07671567797660828 Testing loss 0.0506746731698513 0 model_14 model saved\n",
      "[60 38 23 33 23 16  0  0  0]\n",
      "Training loss 0.02978101372718811 Testing loss 0.034243665635585785 1000 model_14 model saved\n",
      "[59 38 23 33 23 16  0  0  0]\n",
      "Training loss 0.029270954430103302 Testing loss 0.035051748156547546 2000 model_14 model saved\n",
      "[59 37 23 33 22 16  0  0  0]\n",
      "Training loss 0.029031360521912575 Testing loss 0.03537365794181824 3000 model_14 model saved\n",
      "[59 38 23 33 22 16  0  0  0]\n",
      "Training loss 0.028854159638285637 Testing loss 0.03579668328166008 4000 model_14 model saved\n",
      "model_15 is training for dataset of 1\n",
      "Model for 15 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[64 33  1 26 23 12  0  0  0]\n",
      "Training loss 0.12009934335947037 Testing loss 0.06654258072376251 0 model_15 model saved\n",
      "[59 36 19 31 18  0  0  0  0]\n",
      "Training loss 0.05847359448671341 Testing loss 0.07151931524276733 1000 model_15 model saved\n",
      "[59 36 19 30 19  0  0  0  0]\n",
      "Training loss 0.05786708742380142 Testing loss 0.0736231654882431 2000 model_15 model saved\n",
      "[59 36 19 30 19  0  0  0  0]\n",
      "Training loss 0.05752752348780632 Testing loss 0.0747581422328949 3000 model_15 model saved\n",
      "[57 36 18 30 19  0  0  0  0]\n",
      "Training loss 0.05733342096209526 Testing loss 0.07470022141933441 4000 model_15 model saved\n",
      "model_16 is training for dataset of 1\n",
      "Model for 16 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[66 41  0 29 31 16  0  0  0]\n",
      "Training loss 0.057471588253974915 Testing loss 0.03666418418288231 0 model_16 model saved\n",
      "[56 30  0 28  0  0  0  0  0]\n",
      "Training loss 0.030003977939486504 Testing loss 0.019798563793301582 1000 model_16 model saved\n",
      "[56 30  0 28 -1  0  0  0  0]\n",
      "Training loss 0.02989225648343563 Testing loss 0.020017605274915695 2000 model_16 model saved\n",
      "[56 30  0 28  0  0  0  0  0]\n",
      "Training loss 0.029859118163585663 Testing loss 0.020115608349442482 3000 model_16 model saved\n",
      "[56 30  0 28  0  0  0  0  0]\n",
      "Training loss 0.029829399660229683 Testing loss 0.019988328218460083 4000 model_16 model saved\n",
      "model_17 is training for dataset of 1\n",
      "Model for 17 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[385 435 141 291 175  98  57  23   0]\n",
      "Training loss 0.06067676097154617 Testing loss 0.0518561489880085 0 model_17 model saved\n",
      "[346 386 229 251 116  70  34  22   0]\n",
      "Training loss 0.004599741660058498 Testing loss 0.02850121632218361 1000 model_17 model saved\n",
      "[355 381 228 251 120  75  35  22   0]\n",
      "Training loss 0.0029871161095798016 Testing loss 0.02551482431590557 2000 model_17 model saved\n",
      "[355 380 227 247 121  76  35  22   0]\n",
      "Training loss 0.0022262167185544968 Testing loss 0.02384086698293686 3000 model_17 model saved\n",
      "[355 380 227 246 120  78  35  21   0]\n",
      "Training loss 0.0017116143135353923 Testing loss 0.023138253018260002 4000 model_17 model saved\n",
      "model_18 is training for dataset of 1\n",
      "Model for 18 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[399 324 117 212 160 115  59  16   0]\n",
      "Training loss 0.23254503309726715 Testing loss 0.19087208807468414 0 model_18 model saved\n",
      "[487 408 270 241 148 116  41  23   0]\n",
      "Training loss 0.014536481350660324 Testing loss 0.09265004098415375 1000 model_18 model saved\n",
      "[481 412 269 248 150 114  39  22   0]\n",
      "Training loss 0.009245367720723152 Testing loss 0.08296769857406616 2000 model_18 model saved\n",
      "[482 413 271 250 150 113  38  22   0]\n",
      "Training loss 0.00695864949375391 Testing loss 0.07707365602254868 3000 model_18 model saved\n",
      "[480 414 272 252 150 112  37  21   0]\n",
      "Training loss 0.005612176842987537 Testing loss 0.07425189763307571 4000 model_18 model saved\n",
      "model_19 is training for dataset of 1\n",
      "Model for 19 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[115  94  31  63  42  23  28  15   0]\n",
      "Training loss 0.07290160655975342 Testing loss 0.05578172951936722 0 model_19 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119  87  41  64  25  28  23  -1   0]\n",
      "Training loss 0.019544580951333046 Testing loss 0.03783264011144638 1000 model_19 model saved\n",
      "[117  88  41  65  25  26  23   0   0]\n",
      "Training loss 0.01846501976251602 Testing loss 0.03918066993355751 2000 model_19 model saved\n",
      "[115  88  41  64  24  26  23   0   0]\n",
      "Training loss 0.017992017790675163 Testing loss 0.03980502486228943 3000 model_19 model saved\n",
      "[114  89  42  64  23  25  23   0   0]\n",
      "Training loss 0.01769992709159851 Testing loss 0.040238481014966965 4000 model_19 model saved\n",
      "model_20 is training for dataset of 1\n",
      "Model for 20 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[26  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.009628934785723686 Testing loss 0.006157093681395054 0 model_20 model saved\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.009487464092671871 Testing loss 0.0061452388763427734 1000 model_20 model saved\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.009489179588854313 Testing loss 0.0061075338162481785 2000 model_20 model saved\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.009491108357906342 Testing loss 0.0061887591145932674 3000 model_20 model saved\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.00948904175311327 Testing loss 0.006170128006488085 4000 model_20 model saved\n",
      "model_21 is training for dataset of 1\n",
      "Model for 21 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[47 23  1 23 23  0  0  0  0]\n",
      "Training loss 0.11891970038414001 Testing loss 0.04110642522573471 0 model_21 model saved\n",
      "[60 23 20 28  0  0  0  0  0]\n",
      "Training loss 0.07623164355754852 Testing loss 0.05542873218655586 1000 model_21 model saved\n",
      "[61 23 20 29  0  0  0  0  0]\n",
      "Training loss 0.07608728855848312 Testing loss 0.05574333667755127 2000 model_21 model saved\n",
      "[61 23 20 29  0  0  0  0  0]\n",
      "Training loss 0.07605217397212982 Testing loss 0.05572042986750603 3000 model_21 model saved\n",
      "[60 23 20 28  0  0  0  0  0]\n",
      "Training loss 0.07600762695074081 Testing loss 0.05554025247693062 4000 model_21 model saved\n",
      "model_22 is training for dataset of 1\n",
      "Model for 22 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[25  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.008968185633420944 Testing loss 0.006824680138379335 0 model_22 model saved\n",
      "[26  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.008861232548952103 Testing loss 0.006823929492384195 1000 model_22 model saved\n",
      "[26  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.008864395320415497 Testing loss 0.006811110768467188 2000 model_22 model saved\n",
      "[26  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.008860218338668346 Testing loss 0.00680046621710062 3000 model_22 model saved\n",
      "[26  0  0  0  0  0  0  0  0]\n",
      "Training loss 0.008862830698490143 Testing loss 0.0068052466958761215 4000 model_22 model saved\n",
      "model_23 is training for dataset of 1\n",
      "Model for 23 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[186  81  40  76  71  23  18   0   0]\n",
      "Training loss 0.13153629004955292 Testing loss 0.09356709569692612 0 model_23 model saved\n",
      "[175  84  72  84  33  28   0   0   0]\n",
      "Training loss 0.026333745568990707 Testing loss 0.07120642066001892 1000 model_23 model saved\n",
      "[178  83  73  85  32  29   0   0   0]\n",
      "Training loss 0.023150866851210594 Testing loss 0.07203061878681183 2000 model_23 model saved\n",
      "[178  83  73  84  32  29   0   0   0]\n",
      "Training loss 0.021795079112052917 Testing loss 0.0721895843744278 3000 model_23 model saved\n",
      "[180  83  74  85  32  29   0   0   0]\n",
      "Training loss 0.020925166085362434 Testing loss 0.07310954481363297 4000 model_23 model saved\n",
      "model_24 is training for dataset of 1\n",
      "Model for 24 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[250 123  32 102 108  58  24   0   0]\n",
      "Training loss 0.2969021797180176 Testing loss 0.08377113938331604 0 model_24 model saved\n",
      "[228  94  69 108  51  45  21  12   0]\n",
      "Training loss 0.021023796871304512 Testing loss 0.07846902310848236 1000 model_24 model saved\n",
      "[229  92  71 113  50  44  21  11   0]\n",
      "Training loss 0.015309430658817291 Testing loss 0.07527383416891098 2000 model_24 model saved\n",
      "[227  92  71 114  50  44  21  11   0]\n",
      "Training loss 0.012571429833769798 Testing loss 0.07244643568992615 3000 model_24 model saved\n",
      "[230  93  73 115  49  45  21  11   0]\n",
      "Training loss 0.010757692158222198 Testing loss 0.0725426971912384 4000 model_24 model saved\n",
      "model_25 is training for dataset of 1\n",
      "Model for 25 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[32 19  0  0  0  0  0  0  0]\n",
      "Training loss 0.012708482332527637 Testing loss 0.010646023787558079 0 model_25 model saved\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "Training loss 1.467101992602693e-05 Testing loss 2.3857680275796156e-07 1000 model_25 model saved\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "Training loss 1.1554495358723216e-05 Testing loss 3.936686994165939e-07 2000 model_25 model saved\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "Training loss 9.504576155450195e-06 Testing loss 3.434165876115003e-07 3000 model_25 model saved\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "Training loss 7.777880455250852e-06 Testing loss 2.4547327370783023e-07 4000 model_25 model saved\n",
      "model_26 is training for dataset of 1\n",
      "Model for 26 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[67 35 12 24 21 16  0  0  0]\n",
      "Training loss 0.05954291671514511 Testing loss 0.03909379988908768 0 model_26 model saved\n",
      "[56 19  0 22 -1  0  0  0  0]\n",
      "Training loss 0.0357615128159523 Testing loss 0.023347411304712296 1000 model_26 model saved\n",
      "[56 19  0 22  0  0  0  0  0]\n",
      "Training loss 0.035684239119291306 Testing loss 0.0234256349503994 2000 model_26 model saved\n",
      "[57 19  0 22  0  0  0  0  0]\n",
      "Training loss 0.035618651658296585 Testing loss 0.02387135662138462 3000 model_26 model saved\n",
      "[56 19  0 22  0  0  0  0  0]\n",
      "Training loss 0.03559058532118797 Testing loss 0.023449944332242012 4000 model_26 model saved\n",
      "model_27 is training for dataset of 1\n",
      "Model for 27 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[100  59   1  32  36  28  18   0   0]\n",
      "Training loss 0.13615314662456512 Testing loss 0.07912017405033112 0 model_27 model saved\n",
      "[90 41 18 34 23 20  0  0  0]\n",
      "Training loss 0.045554738491773605 Testing loss 0.07730548828840256 1000 model_27 model saved\n",
      "[89 40 18 34 22 20  0  0  0]\n",
      "Training loss 0.044185835868120193 Testing loss 0.07891858369112015 2000 model_27 model saved\n",
      "[88 41 18 34 22 21  0  0  0]\n",
      "Training loss 0.04360323026776314 Testing loss 0.07978826761245728 3000 model_27 model saved\n",
      "[88 40 18 34 22 21  0  0  0]\n",
      "Training loss 0.04314393922686577 Testing loss 0.08055339008569717 4000 model_27 model saved\n",
      "model_28 is training for dataset of 1\n",
      "Model for 28 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[120  37   2  41  58  24   0   0   0]\n",
      "Training loss 0.5822455883026123 Testing loss 0.1659555584192276 0 model_28 model saved\n",
      "[167  52  57  82  34  28   0   0   0]\n",
      "Training loss 0.07725478708744049 Testing loss 0.1947622001171112 1000 model_28 model saved\n",
      "[162  54  56  82  34  27   0   0   0]\n",
      "Training loss 0.06944624334573746 Testing loss 0.19276563823223114 2000 model_28 model saved\n",
      "[164  55  56  83  34  27   0   0   0]\n",
      "Training loss 0.06538612395524979 Testing loss 0.19664818048477173 3000 model_28 model saved\n",
      "[165  56  57  83  33  27   0   0   0]\n",
      "Training loss 0.06313900649547577 Testing loss 0.1980179399251938 4000 model_28 model saved\n",
      "model_29 is training for dataset of 1\n",
      "Model for 29 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[173  92  35  66  59  40  21   0   0]\n",
      "Training loss 0.11500034481287003 Testing loss 0.06553608179092407 0 model_29 model saved\n",
      "[126  48  44  46  26  21  -1   0   0]\n",
      "Training loss 0.020667431876063347 Testing loss 0.037781283259391785 1000 model_29 model saved\n",
      "[123  48  45  46  28  20   0   0   0]\n",
      "Training loss 0.018553797155618668 Testing loss 0.03807225078344345 2000 model_29 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124  49  45  47  29  20   0   0   0]\n",
      "Training loss 0.017365941777825356 Testing loss 0.03866461664438248 3000 model_29 model saved\n",
      "[124  49  45  48  29  19   0   0   0]\n",
      "Training loss 0.016637878492474556 Testing loss 0.039114922285079956 4000 model_29 model saved\n",
      "model_30 is training for dataset of 1\n",
      "Model for 30 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[203  89  31  74  99  43  29   0   0]\n",
      "Training loss 0.13149750232696533 Testing loss 0.07221511006355286 0 model_30 model saved\n",
      "[165  58  54  83  41  26  10   0   0]\n",
      "Training loss 0.013228820636868477 Testing loss 0.05364280939102173 1000 model_30 model saved\n",
      "[165  58  54  82  42  24  10   0   0]\n",
      "Training loss 0.0105519350618124 Testing loss 0.05406089127063751 2000 model_30 model saved\n",
      "[162  59  53  80  42  23  10   0   0]\n",
      "Training loss 0.009298348799347878 Testing loss 0.05402549356222153 3000 model_30 model saved\n",
      "[163  59  53  80  43  22  10   0   0]\n",
      "Training loss 0.008471579290926456 Testing loss 0.054784275591373444 4000 model_30 model saved\n",
      "model_31 is training for dataset of 1\n",
      "Model for 31 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[78 51 16 44 31 16  0  0  0]\n",
      "Training loss 0.07696118205785751 Testing loss 0.046510789543390274 0 model_31 model saved\n",
      "[82 50 23 37 27 15  0  0  0]\n",
      "Training loss 0.0209302119910717 Testing loss 0.03969183191657066 1000 model_31 model saved\n",
      "[82 50 23 38 27 15  0  0  0]\n",
      "Training loss 0.020045218989253044 Testing loss 0.040330179035663605 2000 model_31 model saved\n",
      "[82 51 23 39 27 14  0  0  0]\n",
      "Training loss 0.01968942955136299 Testing loss 0.04051892086863518 3000 model_31 model saved\n",
      "[83 51 23 39 28 14  0  0  0]\n",
      "Training loss 0.019445335492491722 Testing loss 0.04096488654613495 4000 model_31 model saved\n",
      "model_32 is training for dataset of 1\n",
      "Model for 32 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[61 34  1 33 26 18  0  0  0]\n",
      "Training loss 0.12255902588367462 Testing loss 0.06809071451425552 0 model_32 model saved\n",
      "[48 25 18 22 18  0  0  0  0]\n",
      "Training loss 0.0647430494427681 Testing loss 0.06258394569158554 1000 model_32 model saved\n",
      "[49 26 18 22 19  0  0  0  0]\n",
      "Training loss 0.06429872661828995 Testing loss 0.06321169435977936 2000 model_32 model saved\n",
      "[48 26 18 22 19  0  0  0  0]\n",
      "Training loss 0.06404503434896469 Testing loss 0.06347884237766266 3000 model_32 model saved\n",
      "[47 26 18 22 18  0  0  0  0]\n",
      "Training loss 0.0639079362154007 Testing loss 0.0633794367313385 4000 model_32 model saved\n",
      "model_33 is training for dataset of 1\n",
      "Model for 33 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[78 60 15 38 34 20  0  0  0]\n",
      "Training loss 0.1275383085012436 Testing loss 0.07414102554321289 0 model_33 model saved\n",
      "[73 62 32 45 21 13  0  0  0]\n",
      "Training loss 0.03667766973376274 Testing loss 0.06538062542676926 1000 model_33 model saved\n",
      "[74 62 31 45 21 13  0  0  0]\n",
      "Training loss 0.03524603694677353 Testing loss 0.06722182780504227 2000 model_33 model saved\n",
      "[75 63 31 45 22 13  0  0  0]\n",
      "Training loss 0.03454231470823288 Testing loss 0.06872051954269409 3000 model_33 model saved\n",
      "[75 63 31 45 22 13  0  0  0]\n",
      "Training loss 0.034054916352033615 Testing loss 0.06984635442495346 4000 model_33 model saved\n",
      "model_34 is training for dataset of 1\n",
      "Model for 34 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[108  71  25  37  62  21  16   0   0]\n",
      "Training loss 0.20522558689117432 Testing loss 0.08904740959405899 0 model_34 model saved\n",
      "[132 101  65  78  41  30  17   0   0]\n",
      "Training loss 0.030169257894158363 Testing loss 0.09625356644392014 1000 model_34 model saved\n",
      "[129 101  65  78  40  29  17   0   0]\n",
      "Training loss 0.02668176032602787 Testing loss 0.09530787914991379 2000 model_34 model saved\n",
      "[128 102  66  78  39  29  17   0   0]\n",
      "Training loss 0.024998364970088005 Testing loss 0.09520436823368073 3000 model_34 model saved\n",
      "[128 101  66  77  39  29  16   0   0]\n",
      "Training loss 0.023894913494586945 Testing loss 0.09520464390516281 4000 model_34 model saved\n",
      "model_35 is training for dataset of 1\n",
      "Model for 35 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[83 71 19 33 40 25 12  0  0]\n",
      "Training loss 0.10899496078491211 Testing loss 0.07267915457487106 0 model_35 model saved\n",
      "[85 53 29 46 22 15 -1  0  0]\n",
      "Training loss 0.036332689225673676 Testing loss 0.058772556483745575 1000 model_35 model saved\n",
      "[85 52 29 46 21 14  0  0  0]\n",
      "Training loss 0.03501160070300102 Testing loss 0.060231518000364304 2000 model_35 model saved\n",
      "[85 51 29 46 20 13  0  0  0]\n",
      "Training loss 0.03439386934041977 Testing loss 0.06089871749281883 3000 model_35 model saved\n",
      "[85 50 28 47 20 13  0  0  0]\n",
      "Training loss 0.033909812569618225 Testing loss 0.06189349666237831 4000 model_35 model saved\n",
      "model_36 is training for dataset of 1\n",
      "Model for 36 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[409 265  75 202 182 106  58  11   0]\n",
      "Training loss 0.13959503173828125 Testing loss 0.08628930151462555 0 model_36 model saved\n",
      "[283 186 121 158  77  68  20   0   0]\n",
      "Training loss 0.012382532469928265 Testing loss 0.03726771101355553 1000 model_36 model saved\n",
      "[283 182 119 153  73  67  21   0   0]\n",
      "Training loss 0.007977556437253952 Testing loss 0.033896032720804214 2000 model_36 model saved\n",
      "[283 179 120 152  75  66  21   0   0]\n",
      "Training loss 0.0060968343168497086 Testing loss 0.033039458096027374 3000 model_36 model saved\n",
      "[281 177 119 152  75  63  22   0   0]\n",
      "Training loss 0.004847729578614235 Testing loss 0.03139628469944 4000 model_36 model saved\n",
      "model_37 is training for dataset of 1\n",
      "Model for 37 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[146  96  33  71  59  36  15   0   0]\n",
      "Training loss 0.1096646711230278 Testing loss 0.07525340467691422 0 model_37 model saved\n",
      "[108  80  39  51  35  16   0   0   0]\n",
      "Training loss 0.02475520223379135 Testing loss 0.049361299723386765 1000 model_37 model saved\n",
      "[110  78  39  55  34  16   0   0   0]\n",
      "Training loss 0.02333146519958973 Testing loss 0.053008053451776505 2000 model_37 model saved\n",
      "[110  76  39  56  34  16  -1   0   0]\n",
      "Training loss 0.02256256900727749 Testing loss 0.05434318259358406 3000 model_37 model saved\n",
      "[109  75  39  58  34  16   0   0   0]\n",
      "Training loss 0.022085439413785934 Testing loss 0.05538700148463249 4000 model_37 model saved\n",
      "model_38 is training for dataset of 1\n",
      "Model for 38 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[135 112  23  81  66  29  28   0   0]\n",
      "Training loss 0.11231234669685364 Testing loss 0.080374576151371 0 model_38 model saved\n",
      "[149 126  76  80  35  41  -1   0   0]\n",
      "Training loss 0.021333320066332817 Testing loss 0.06743592023849487 1000 model_38 model saved\n",
      "[147 128  76  78  37  42   0   0   0]\n",
      "Training loss 0.01895710453391075 Testing loss 0.0662536472082138 2000 model_38 model saved\n",
      "[144 129  76  79  37  41   0   0   0]\n",
      "Training loss 0.017759479582309723 Testing loss 0.06511849910020828 3000 model_38 model saved\n",
      "[142 129  76  77  37  41   0   0   0]\n",
      "Training loss 0.01693471148610115 Testing loss 0.0644042119383812 4000 model_38 model saved\n",
      "model_39 is training for dataset of 1\n",
      "Model for 39 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[85 57 20 34 32 18  0  0  0]\n",
      "Training loss 0.08312789350748062 Testing loss 0.054235123097896576 0 model_39 model saved\n",
      "[81 51 28 34 19 16  0  0  0]\n",
      "Training loss 0.026120157912373543 Testing loss 0.048437826335430145 1000 model_39 model saved\n",
      "[81 50 29 34 19 16  0  0  0]\n",
      "Training loss 0.02525445632636547 Testing loss 0.049400363117456436 2000 model_39 model saved\n",
      "[83 50 28 35 18 17  0  0  0]\n",
      "Training loss 0.024806760251522064 Testing loss 0.04937756434082985 3000 model_39 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84 50 29 35 18 17  0  0  0]\n",
      "Training loss 0.024566898122429848 Testing loss 0.049831561744213104 4000 model_39 model saved\n",
      "model_40 is training for dataset of 1\n",
      "Model for 40 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[206 160  51  97  98  55  30  11   0]\n",
      "Training loss 0.11656951904296875 Testing loss 0.06941759586334229 0 model_40 model saved\n",
      "[253 184 101 129  85  60  29  18   0]\n",
      "Training loss 0.008156612515449524 Testing loss 0.04712992161512375 1000 model_40 model saved\n",
      "[251 183 101 130  81  58  28  17   0]\n",
      "Training loss 0.0059544239193201065 Testing loss 0.044677965342998505 2000 model_40 model saved\n",
      "[249 181 101 128  80  58  28  16   0]\n",
      "Training loss 0.004877700470387936 Testing loss 0.043364547193050385 3000 model_40 model saved\n",
      "[247 178 100 126  79  57  28  15   0]\n",
      "Training loss 0.004146382212638855 Testing loss 0.04250069335103035 4000 model_40 model saved\n",
      "model_41 is training for dataset of 1\n",
      "Model for 41 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[80 67 14 33 30 27 17  0  0]\n",
      "Training loss 0.08600909262895584 Testing loss 0.0597374327480793 0 model_41 model saved\n",
      "[82 51 26 33 24 20  0  0  0]\n",
      "Training loss 0.026715731248259544 Testing loss 0.041611287742853165 1000 model_41 model saved\n",
      "[84 50 27 33 24 20  0  0  0]\n",
      "Training loss 0.02591184340417385 Testing loss 0.04231758415699005 2000 model_41 model saved\n",
      "[85 50 27 33 25 21  0  0  0]\n",
      "Training loss 0.02543077990412712 Testing loss 0.04281197860836983 3000 model_41 model saved\n",
      "[85 50 27 33 25 20  0  0  0]\n",
      "Training loss 0.025191782042384148 Testing loss 0.04306542128324509 4000 model_41 model saved\n",
      "model_42 is training for dataset of 1\n",
      "Model for 42 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[167 132  50  97  71  51  24  11   0]\n",
      "Training loss 0.05119578167796135 Testing loss 0.038802824914455414 0 model_42 model saved\n",
      "[118  93  64  76  30  21  14   0   0]\n",
      "Training loss 0.00790471863001585 Testing loss 0.019659558311104774 1000 model_42 model saved\n",
      "[117  90  65  77  29  20  14   0   0]\n",
      "Training loss 0.006671130657196045 Testing loss 0.0201856791973114 2000 model_42 model saved\n",
      "[116  91  65  79  30  19  14   0   0]\n",
      "Training loss 0.006150803063064814 Testing loss 0.020811090245842934 3000 model_42 model saved\n",
      "[116  92  64  80  31  19  13   0   0]\n",
      "Training loss 0.005758227314800024 Testing loss 0.021073969081044197 4000 model_42 model saved\n",
      "model_43 is training for dataset of 1\n",
      "Model for 43 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[432 245 114 220 146  83  54  19   0]\n",
      "Training loss 0.05386721342802048 Testing loss 0.03377586975693703 0 model_43 model saved\n",
      "[509 269 210 249 116 102  50  18   0]\n",
      "Training loss 0.004079208709299564 Testing loss 0.028911365196108818 1000 model_43 model saved\n",
      "[513 267 215 238 115 104  52  19   0]\n",
      "Training loss 0.002736065536737442 Testing loss 0.02786351926624775 2000 model_43 model saved\n",
      "[510 270 216 239 114 106  51  18   0]\n",
      "Training loss 0.002091303002089262 Testing loss 0.02707715518772602 3000 model_43 model saved\n",
      "[506 272 216 239 111 107  52  18   0]\n",
      "Training loss 0.0016733474330976605 Testing loss 0.026683947071433067 4000 model_43 model saved\n",
      "model_44 is training for dataset of 1\n",
      "Model for 44 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[205 165  47 104 106  40  21  16   0]\n",
      "Training loss 0.06465976685285568 Testing loss 0.04929202049970627 0 model_44 model saved\n",
      "[154 121  73  84  49  29  22   0   0]\n",
      "Training loss 0.007797854021191597 Testing loss 0.028165968134999275 1000 model_44 model saved\n",
      "[152 123  72  81  48  29  21  -1   0]\n",
      "Training loss 0.006356858182698488 Testing loss 0.02755982056260109 2000 model_44 model saved\n",
      "[154 124  73  81  48  29  21   0   0]\n",
      "Training loss 0.005591185297816992 Testing loss 0.0274143535643816 3000 model_44 model saved\n",
      "[153 124  74  81  48  29  22   0   0]\n",
      "Training loss 0.0051070754416286945 Testing loss 0.027303215116262436 4000 model_44 model saved\n",
      "model_45 is training for dataset of 1\n",
      "Model for 45 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[72 80 26 59 26 20 13  0  0]\n",
      "Training loss 0.08196181803941727 Testing loss 0.05128786712884903 0 model_45 model saved\n",
      "[72 67 34 33 17 21 -1  0  0]\n",
      "Training loss 0.02636721171438694 Testing loss 0.048436008393764496 1000 model_45 model saved\n",
      "[71 68 34 33 18 21 -1  0  0]\n",
      "Training loss 0.02552643045783043 Testing loss 0.04994096979498863 2000 model_45 model saved\n",
      "[69 67 34 33 17 21 -1  0  0]\n",
      "Training loss 0.02510679140686989 Testing loss 0.05013107508420944 3000 model_45 model saved\n",
      "[69 68 33 32 18 20 -1  0  0]\n",
      "Training loss 0.024837510660290718 Testing loss 0.05077551677823067 4000 model_45 model saved\n",
      "model_46 is training for dataset of 1\n",
      "Model for 46 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[54 63 21 37 27  9 10  0  0]\n",
      "Training loss 0.0391915962100029 Testing loss 0.03320451080799103 0 model_46 model saved\n",
      "[51 41 24 32 17  0  0  0  0]\n",
      "Training loss 0.01758486218750477 Testing loss 0.02233336865901947 1000 model_46 model saved\n",
      "[51 41 24 32 17  0  0  0  0]\n",
      "Training loss 0.017350131645798683 Testing loss 0.022562680765986443 2000 model_46 model saved\n",
      "[51 41 24 32 17  0  0  0  0]\n",
      "Training loss 0.01721084490418434 Testing loss 0.022689176723361015 3000 model_46 model saved\n",
      "[51 41 24 32 17  0  0  0  0]\n",
      "Training loss 0.017128989100456238 Testing loss 0.02279891073703766 4000 model_46 model saved\n",
      "model_47 is training for dataset of 1\n",
      "Model for 47 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[12 11  9  7  0  0  0  0  0]\n",
      "Training loss 0.018552005290985107 Testing loss 0.004714145790785551 0 model_47 model saved\n",
      "[ 0 22  0  0  0  0  0  0  0]\n",
      "Training loss 0.009985608048737049 Testing loss 0.004465247038751841 1000 model_47 model saved\n",
      "[ 0 22  0  0  0  0  0  0  0]\n",
      "Training loss 0.00998283177614212 Testing loss 0.004382894840091467 2000 model_47 model saved\n",
      "[ 0 22  0  0  0  0  0  0  0]\n",
      "Training loss 0.009987400844693184 Testing loss 0.00440928665921092 3000 model_47 model saved\n",
      "[ 0 22  0  0  0  0  0  0  0]\n",
      "Training loss 0.009979712776839733 Testing loss 0.004322826396673918 4000 model_47 model saved\n",
      "model_48 is training for dataset of 1\n",
      "Model for 48 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[121  77  50  67  36  21  11   0   0]\n",
      "Training loss 0.04986928403377533 Testing loss 0.03633924573659897 0 model_48 model saved\n",
      "[146  98  77  70  31  29  18   0   0]\n",
      "Training loss 0.012424810789525509 Testing loss 0.030448274686932564 1000 model_48 model saved\n",
      "[146  98  78  70  31  29  17   0   0]\n",
      "Training loss 0.011675984598696232 Testing loss 0.029937386512756348 2000 model_48 model saved\n",
      "[147  99  79  71  31  29  17   0   0]\n",
      "Training loss 0.01123246643692255 Testing loss 0.02975953370332718 3000 model_48 model saved\n",
      "[148  99  79  71  31  30  17   0   0]\n",
      "Training loss 0.010963100008666515 Testing loss 0.029748069122433662 4000 model_48 model saved\n",
      "model_49 is training for dataset of 1\n",
      "Model for 49 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[64 71 24 54 21 18  0  0  0]\n",
      "Training loss 0.052869219332933426 Testing loss 0.047713615000247955 0 model_49 model saved\n",
      "[70 69 44 30 23  0  0  0  0]\n",
      "Training loss 0.024840498343110085 Testing loss 0.03485846519470215 1000 model_49 model saved\n",
      "[71 69 46 31 24  0  0  0  0]\n",
      "Training loss 0.024348780512809753 Testing loss 0.03536972030997276 2000 model_49 model saved\n",
      "[72 69 46 32 24  0  0  0  0]\n",
      "Training loss 0.024191485717892647 Testing loss 0.03545607998967171 3000 model_49 model saved\n",
      "[72 69 46 32 24  0  0  0  0]\n",
      "Training loss 0.024098269641399384 Testing loss 0.03530144691467285 4000 model_49 model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_50 is training for dataset of 1\n",
      "Model for 50 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[33 20 13 18 11  0  0  0  0]\n",
      "Training loss 0.03772486373782158 Testing loss 0.018544543534517288 0 model_50 model saved\n",
      "[40 18 19 16  0  0  0  0  0]\n",
      "Training loss 0.02755897305905819 Testing loss 0.01601320505142212 1000 model_50 model saved\n",
      "[39 18 19 16  0  0  0  0  0]\n",
      "Training loss 0.027491312474012375 Testing loss 0.016142701730132103 2000 model_50 model saved\n",
      "[40 19 20 16  0  0  0  0  0]\n",
      "Training loss 0.027451252564787865 Testing loss 0.01644742488861084 3000 model_50 model saved\n",
      "[40 18 20 16  0  0  0  0  0]\n",
      "Training loss 0.027442317456007004 Testing loss 0.01639304682612419 4000 model_50 model saved\n",
      "model_51 is training for dataset of 1\n",
      "Model for 51 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[549 559 257 321 290 134  80  37   0]\n",
      "Training loss 0.026134595274925232 Testing loss 0.0232631154358387 0 model_51 model saved\n",
      "[612 647 448 470 185 119  38  14   0]\n",
      "Training loss 0.0028303894214332104 Testing loss 0.01692027971148491 1000 model_51 model saved\n",
      "[608 644 445 463 185 120  37  12   0]\n",
      "Training loss 0.001765947206877172 Testing loss 0.015660036355257034 2000 model_51 model saved\n",
      "[618 638 445 465 187 119  37  12   0]\n",
      "Training loss 0.0013065908569842577 Testing loss 0.015117035247385502 3000 model_51 model saved\n",
      "[626 639 450 467 187 120  36  12   0]\n",
      "Training loss 0.0010132809402421117 Testing loss 0.014924898743629456 4000 model_51 model saved\n",
      "model_52 is training for dataset of 1\n",
      "Model for 52 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[119 108  35  94  47  17  18   0   0]\n",
      "Training loss 0.11377453804016113 Testing loss 0.05780286714434624 0 model_52 model saved\n",
      "[125 126  98  75  27  29   0   0   0]\n",
      "Training loss 0.02334277518093586 Testing loss 0.08795548230409622 1000 model_52 model saved\n",
      "[120 125  97  76  26  27   0   0   0]\n",
      "Training loss 0.021180056035518646 Testing loss 0.0862605944275856 2000 model_52 model saved\n",
      "[117 123  97  75  26  26   0   0   0]\n",
      "Training loss 0.020198820158839226 Testing loss 0.08795224130153656 3000 model_52 model saved\n",
      "[113 122  96  75  25  25   0   0   0]\n",
      "Training loss 0.019551025703549385 Testing loss 0.0875067263841629 4000 model_52 model saved\n",
      "model_53 is training for dataset of 1\n",
      "Model for 53 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[133 165  62  98  61  36  21   0   0]\n",
      "Training loss 0.047133948653936386 Testing loss 0.038739655166864395 0 model_53 model saved\n",
      "[155 132  95  68  36  26   0   0   0]\n",
      "Training loss 0.0070123132318258286 Testing loss 0.0181261133402586 1000 model_53 model saved\n",
      "[155 137  93  66  35  26   0   0   0]\n",
      "Training loss 0.00549366744235158 Testing loss 0.017896484583616257 2000 model_53 model saved\n",
      "[154 139  92  64  36  27   0   0   0]\n",
      "Training loss 0.004851799923926592 Testing loss 0.01806107722222805 3000 model_53 model saved\n",
      "[155 140  93  65  37  27   0   0   0]\n",
      "Training loss 0.004467453807592392 Testing loss 0.01844075508415699 4000 model_53 model saved\n",
      "model_54 is training for dataset of 1\n",
      "Model for 54 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[132 169  54  96  62  33  27   0   0]\n",
      "Training loss 0.06410754472017288 Testing loss 0.04574586823582649 0 model_54 model saved\n",
      "[147 141  90  85  27  34  16   0   0]\n",
      "Training loss 0.011255470104515553 Testing loss 0.03549551963806152 1000 model_54 model saved\n",
      "[146 139  89  86  25  33  15   0   0]\n",
      "Training loss 0.009957125410437584 Testing loss 0.035018190741539 2000 model_54 model saved\n",
      "[146 139  87  86  25  32  15   0   0]\n",
      "Training loss 0.009275652468204498 Testing loss 0.03492132946848869 3000 model_54 model saved\n",
      "[146 141  86  87  25  33  15   0   0]\n",
      "Training loss 0.008843086659908295 Testing loss 0.035343803465366364 4000 model_54 model saved\n",
      "model_55 is training for dataset of 1\n",
      "Model for 55 loaded from saved state.\n",
      "torch.Size([540, 60, 9]) torch.Size([61, 60, 9]) torch.Size([540, 60, 9]) torch.Size([61, 60, 9])\n",
      "[48 70 22 38 24  0  0  0  0]\n",
      "Training loss 0.05186592787504196 Testing loss 0.03945494815707207 0 model_55 model saved\n",
      "[31 33 25 25  0  0  0  0  0]\n",
      "Training loss 0.025732532143592834 Testing loss 0.022558648139238358 1000 model_55 model saved\n",
      "[30 34 26 25  0  0  0  0  0]\n",
      "Training loss 0.02556629665195942 Testing loss 0.022933190688490868 2000 model_55 model saved\n",
      "[31 34 26 25  0  0  0  0  0]\n",
      "Training loss 0.02551046572625637 Testing loss 0.023052148520946503 3000 model_55 model saved\n",
      "[31 34 25 26  0  0  0  0  0]\n",
      "Training loss 0.025436392053961754 Testing loss 0.02315806970000267 4000 model_55 model saved\n"
     ]
    }
   ],
   "source": [
    "wilayat_models = {}\n",
    "for dataset_i, df in enumerate(data_frames):\n",
    "    df_time_range = df[(df['Time'] >= start_time) & (df['Time'] <= end_time)]\n",
    "    \n",
    "    for wilayat_id in df_time_range['WILAYAT_CODE'].unique():\n",
    "        \n",
    "        wilayat_data_frames[wilayat_id] = df_time_range[df_time_range['WILAYAT_CODE'] == wilayat_id].copy()\n",
    "        wilayat_data_frames[wilayat_id].set_index('Time', inplace=True)\n",
    "        wilayat_data_frames[wilayat_id].drop(columns=['WILAYAT_CODE', 'REGION_ID', 'CITIZENID'], inplace=True)\n",
    "        wilayat_data_frames[wilayat_id] = wilayat_data_frames[wilayat_id].groupby('Time').sum()\n",
    "        wilayat_data_frames[wilayat_id] = wilayat_data_frames[wilayat_id].reindex(all_times)\n",
    "        wilayat_data_frames[wilayat_id].fillna(0, inplace=True)\n",
    "\n",
    "    for wilayat_id, wilayat_df in wilayat_data_frames.items():\n",
    "        \n",
    "        input_sequences,target_sequences,scaler = outlier_replacement(wilayat_df, wilayat_id)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_sequences, target_sequences, test_size=test_size, shuffle=False)\n",
    "        print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        train_inputs = torch.Tensor(X_train).to(device)\n",
    "        train_targets = torch.Tensor(y_train).to(device)\n",
    "        test_inputs = torch.Tensor(X_test).to(device)\n",
    "        test_targets = torch.Tensor(y_test).to(device)\n",
    "        model = wilayat_models[wilayat_id].to(device)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00002)\n",
    "\n",
    "        train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(test_inputs, test_targets)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        writer = SummaryWriter(f\"runs3/WilayatID_{wilayat_id}\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for inputs, targets in train_loader:\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward() \n",
    "                optimizer.step()\n",
    "                writer.add_scalar('Training loss', loss.item(), epoch)\n",
    "\n",
    "            if epoch %1000 == 0:        \n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for inputs, targets in test_loader:\n",
    "                        inputs = inputs.to(device)\n",
    "                        targets = targets.to(device)\n",
    "                        test_outputs = model(inputs)\n",
    "                        mse = criterion(test_outputs, targets).item()\n",
    "                        writer.add_scalar('Testing loss', mse, epoch)\n",
    "                        test_outputs_np = test_outputs.cpu().numpy()  \n",
    "                        reshaped_outputs = test_outputs_np.reshape(-1,test_outputs_np.shape[-2] ,test_outputs_np.shape[-1])\n",
    "                        reshaped_outputs = np.sum(reshaped_outputs , axis=1)\n",
    "                        original_scale_outputs = scaler.inverse_transform(reshaped_outputs)\n",
    "                        original_scale_outputs_rounded = np.round(original_scale_outputs).astype(int)\n",
    "                        print(original_scale_outputs_rounded[-1])\n",
    "\n",
    "                torch.save(model, f'/home/aiadmin1/Desktop/OMAN_AI_PROJECT/Transformer44M_2/model_{wilayat_id}.pt')\n",
    "                print('Training loss', loss.item(), 'Testing loss', mse, epoch, f\"model_{wilayat_id} model saved\")\n",
    "\n",
    "        writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
